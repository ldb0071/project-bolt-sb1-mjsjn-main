Page 13

Figure 5: Calc/DysCalc, Top 3 Affi-F1 variants per mode

<!-- image -->

Figure 6: Vision/Text, Top 3 Affi-F1 variants per modality

<!-- image -->

Figure 7: Subsampled/Original, 0-shot raw text vs 30% text

<!-- image -->

Interestingly, when we explicitly use CoT to simulate human-like reasoning about time series, the anomaly detection performance steadily drops across all models and anomaly types, as shown in Figure 2. These findings suggest that LLMs' performance in time series anomaly detection may not rely on the kind of step-by-step logical reasoning that CoT prompting aims to elicit. However, this does not necessarily mean LLMs use no reasoning at all; rather, their approach to understanding time series data may differ from our expectations of explicit, human-like reasoning processes.

## Rejected Hypothesis 2 on Repetition Bias

LLMs' repetition bias does not explain their ability to identify periodic structures.