## B.1 Performer-based autoencoder

For the Performer-based autoencoder M pt , the input with the shape ( batch, W, D ) is passed through a plain Performer with N perf layers after the positional embedding step, where W represents the input window size. This is followed by a linear encoding layer that transforms the dimensionality from D to D lat , resulting in the shape ( batch, W, D lat ) for the latent variables. In the case of M pt , there is no compression along the time domain. The latent variables then pass through another linear decoding layer that transforms the dimensionality from D lat back to D , followed by another Performer with N perf layers.

## B.2 Performer-based stacked encoder

For the Performer-based stacked encoder M seq , the input with shape ( batch, W 0 , D ) is passed through a plain Performer with one layer after the positional embedding step, followed by a linear encoding layer that transforms the window size from W 0 to W 1 , where W 0 = 2 γ (cf. section 3.6). It should be noted that unlike M pt , compression is done along the time domain for M seq . The one-layer Performer and linear layer are stacked N enc times, where in the i -th stack, the window size is compressed from W i -1 to W i . W N enc is equal to the target output window size δ . For both M pt and M seq , we optimize N perf , D lat , W , N enc , W i for i ∈ { 0 , ..., N enc } , and δ for the best performance. Note that M seq isn't capable of reconstructing the first and last γ time points due to its architecture, hence we discard the first and last γ points reconstructed by M pt so that rest of the time points have exactly two reconstructed values corresponding to using M seq and M pt , respectively.