## 3.5 Point-based Reconstruction Models

Consider some model M pt that reconstructs each time point t point-wise: ˆ x pt,t ≜ M pt ( x 0 t ) . Using M pt , a method for yielding the anomaly score is by using the point-based reconstruction mean-squared error, defined as a pt = { a pt, 1 , ..., a pt,T } , where a pt,t ≜ ∥ ˆ x pt,t -x 0 t ∥ 2 2 . One concern for using this kind of anomaly score is that we are not taking into account any time-dependent relationships for deriving a pt , so simply using M pt and a pt can barely be classified as a time series anomaly detection approach. Surprisingly, however, we find that a simple realization of M pt can already achieve impressive results for F1 ∗ (section 4.4).

Since M pt learns to capture the distribution of all normal point data, we assume that ˆ x pt,t ∈ X ∗ or is very close. Moreover, since ˆ x pt,t can offset point-anomalies, we assume x c t ≈ ˆ x pt,t , and implement a point-based reconstruction model to calculate ˆ x pt,t in practice.

X c = { x c 1 , ..., x c T } ≈ ˆ X c = { ˆ x c 1 , ..., ˆ x c T } , ˆ x c t = ˆ x pt,t = M pt ( x 0 t ) (15)

M pt can be any model that has the ability to reconstruct X 0 point-wise. To our surprise, the best performance can be achieved by using a simple Performer-based autoencoder ([34]) that actually has the potential to discover temporal information. Despite having such a possibility, it only learned to reconstruct point-by-point during training. We demonstrated this fact by shuffling the input time points and observing that the result will be the same after reordering the output sequence. One possible explanation is that during training, it is a lot easier to individually reconstruct single time points than to find complex time-dependent relationships; and since the Performer-based autoencoder tries to optimize over a batch of time points, this reduces the effect of overfitting and allows the model to better generalize to unseen data. However, the exact reason for this remains an open question. For the rest of the study, we will use M pt to refer to the Performer-based autoencoder model. Details for the architecture of M pt are shown in Appendix B.1.