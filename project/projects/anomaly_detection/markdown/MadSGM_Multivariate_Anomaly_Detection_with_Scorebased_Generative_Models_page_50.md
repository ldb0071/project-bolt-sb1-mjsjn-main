Deep neural networks in the image domain are known to have a high vulnerability to adversarial attacks using the adversarially perturbed images to cause misclassi/fication. As a defense strategy against such attacks, there is adversarial puri/fication that puri/fies perturbed images into clean images. Many existing puri/fication methods focused on deep generative models. Defense-GAN [24] reduces the e/ffect of the adversarial perturbation using a WGANbased method. Yoon et al. [39] utilizes an energy-based model trained using denoising score matching. Di/ffPure [19] removes noises from attacked images via the forward and reverse SDEs in SGM [30], whose main intuition is that gradually reducing noises in the reverse process is similar to the role of the puri/fication model. We further enhance our method by adopting this adversarial puri/fication idea.