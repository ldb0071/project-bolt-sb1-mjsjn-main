Page 1

## Can LLMs Serve As Time Series Anomaly Detectors?

Manqing Dong † , Hao Huang ‡ , and Longbing Cao †

† School of Computing, Macquarie University ‡ School of Computer Science, University of Technology Sydney

## Abstract

An emerging topic in large language models (LLMs) is their application to time series forecasting, characterizing mainstream and patternable characteristics of time series. A relevant but rarely explored and more challenging question is whether LLMs can detect and explain time series anomalies, a critical task across various real-world applications. In this paper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3, in detecting and explaining anomalies in time series. Our studies reveal that: 1) LLMs cannot be directly used for time series anomaly detection. 2) By designing prompt strategies such as in-context learning and chain-of-thought prompting, GPT-4 can detect time series anomalies with results competitive to baseline methods. 3) We propose a synthesized dataset to automatically generate time series anomalies with corresponding explanations. By applying instruction fine-tuning on this dataset, LLaMA3 demonstrates improved performance in time series anomaly detection tasks. In summary, our exploration shows the promising potential of LLMs as time series anomaly detectors.

## 1 Introduction

With the capabilities of Large Language Models (LLMs) demonstrated in handling various tasks, particularly for natural language processing (NLP) [Achiam et al., 2023] and computer vision (CV) [Liu et al., 2024b], LLMs-based time series analysis emerges as a promising topic [Zhang et al., 2024]. Their primary focus is on time series forecasting, which is an increasingly concerned topic for its broad and lasting roles in wide applications. Their studies can be broadly classified into two groups: (1) prompt engineering approaches, where time series are treated as a series of tokens, either directly fed into the LLMs [Gruver et al., 2023] or combined with instruction prompts [Xue and Salim, 2023], to conduct time series forecasting in a sentence-to-sentence fashion; and (2) aligning approaches, which use LLMs as backbones to train encoders transforming time series into embeddings and decoders translating the LLM outputs into the required output, or even utilizing the middle layers of the LLMs via strategies like pretraining [Ansari et al., 2024] or parameter-efficient fine-tuning (PEFT) [He et al., 2022, Zhou et al., 2023, Jin et al., 2024]. In contrast, time series anomaly detection, while increasingly studied in deep anomaly detection [Pang et al., 2021], has been rarely explored in the realm of LLMs.

LLMs-based time series anomaly detection exhibits significant challenges differing from LLMs-based time series forecasting. The latter captures mainstream and patternable characteristics in time series, while the former needs to handle anomaly complexities including point and contextual exceptions. The limited work available on LLMs for time series anomaly detection [Zhou et al., 2023, Zhang et al., 2023, Liu et al., 2024a] does not explicitly verify or address these issues. They also overlook the textual reasoning ability of LLMs, treating both the input and output of LLMs as time series, without the explanation of how LLMs make their decisions. This motivates us to investigate an important capability area of LLMs in this paper: can LLMs serve as explainable time series anomaly detectors?

First, inspired by the work on treating LLMs as zero-shot learners for time series forecasting through prompt engineering [Gruver et al., 2023, Liu et al., 2024c], we investigate whether LLMs can understand general anomaly-sensitive patterns in time series and explain their decisions, which are essential for time series anomaly detection tasks. Second, time series anomalies can present in different forms, such as point anomalies and contextual anomalies. Therefore, we explore not only whether LLMs can detect time series anomalies but also whether they can identify specific types of anomalies. This approach goes beyond treating time series anomaly detection as a binary classification task [Zhou et al., 2023, Zhang et al., 2023].

Specifically, we investigate the ability of two representative LLMs, GPT-4 [Achiam et al., 2023] and LLaMA3 1 , for time series anomaly detection and their explainability by addressing three questions: (1) Can LLMs be directly applied for explainable time series anomaly detection? Unfortunately, the answer is no, leading us to the next question: (2) How can LLMs detect and explain time series anomalies via designing appropriate prompt strategies? Through various tests, we find that GPT4 often excels as an explainable time series anomaly detector with minimal prompt instructions. However, our study also reveals gaps in the performance of smaller LLMs, i.e., LLaMA3, in promptbased time series anomaly detection. This brings us to our final question: (3) Can we improve LLMs' detection performance by designing proper instruction fine-tuning? Since there is no available time series data with both anomalies and explanations for instruction fine-tuning, we propose a Time Series and Text Explanation Generator (TTGenerator) to automatically generate time series with anomalies and corresponding descriptions for base and anomaly patterns. We demonstrate the augmentation and benchmarking roles of this dataset in enhancing LLM-based time series anomaly detection.

In a nutshell, our contributions include:

- · Comprehensively investigating the zero-shot learning performance of LLMs in time series anomaly detection tasks and their explanatory capabilities.
- · Proposing strategic prompt engineering enabling advanced LLMs to achieve competent performance in anomaly detection, compared to baseline methods.
- · Introducing a synthesized dataset for fine-tuning LLMs, enhancing their performance in time series anomaly detection tasks post fine-tuning.