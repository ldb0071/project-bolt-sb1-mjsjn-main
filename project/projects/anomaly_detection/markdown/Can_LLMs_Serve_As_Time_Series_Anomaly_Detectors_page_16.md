Page 16

Figure 9: Template for time series anomaly pattern explanation - point-aware anomalies.

<!-- image -->

larger ratio to be 1.5 to 3 times the original values, and the smaller ratio to be 0.25 to 0.75 of the original values. A period change, i.e., a modified ˜ ω n in s ( T i,j ) , can also occur. We randomly sample whether the period becomes longer or shorter, with the longer ratio being 1.5 to 3, and the shorter ratio being 0.25 to 0.75.

Trend anomalies occur when there is a change point where trends differ before and after point i , with 1 < i < N . We set the change point between 0.2 to 0.8 of the time series and randomly select whether the trend is increasing or decreasing by 1.5 to 5 times the standard deviation of the base time series. A trend break occurs where the trend changes at i and then reverts at j , with 1 < i < j < N . We set i in the 0.2 to 0.8 position of the time series and j -i to be about 0.05 to 0.2 of the length of the time series. We randomly decide whether the trend break is increasing or decreasing, with the change being 1.5 to 5 times the standard deviation of the base time series.

Shape anomalies may occur as a pattern change, where the base pattern shifts starting at i , with 1 < i < N . We randomly select the start point in the 0.2 to 0.6 range of the original time series. A pattern break occurs where the base pattern changes at i but returns to normal by j , with 1 < i < j < N . We set the start point i in the 0.2 to 0.6 range of the original time series, and the break length to be 0.2 to 0.4 of the original time series. Specifically, to generate shape anomalies, we use a different seasonality type from the original time series and reuse TTGenerator to create a new base time series with the targeted seasonality type. For example, if the original time series has sine wave seasonality, we generate a new time series with IFFT seasonality to insert as shape anomalies.

To generate anomalies in a time series, we first randomly select 1-3 types from the five anomaly categories: global point anomaly, local point anomaly, seasonality anomaly, shape anomaly, and trend anomaly. If a seasonality, shape, or trend anomaly is selected, we further specify the downstream anomaly type. For example, for a trend anomaly, we randomly select whether it is a shape change or a shape break.

Explanation Generation The templates used to generate descriptions for the base time series are shown in Figure 8. We concatenate the descriptions for the trend, seasonality, and noise components to form the overall description of the base time series. Note that if the time series lacks a trend, we omit any trend-related description. The templates used to generate explanations for the anomalies are shown in Figure 9 and Figure 10. We concatenate the descriptions of the anomalies in a time series to form the overall anomaly explanation for that time series.

Examples for the Generated Samples Figure 11 shows examples of the base time series generation results and their corresponding automatically generated explanations. Figure 12 illustrates examples of global and local point anomalies. Figure 13 presents examples of seasonality anomalies. Figure 14

Figure 10: Template for time series anomaly pattern explanation - context-aware anomalies.

<!-- image -->

displays examples of trend anomalies, and Figure 15 demonstrates examples of shape anomalies. Note that all explanations are automatically generated by our template and will be further refined by GPT-4.

Formalization to Instruction Dataset Specifically, a single data sample includes the time series values, labels for the anomalies, labels for the specific types of anomalies, an explanation for the base time series only, an explanation for the anomalies only, an explanation including both the base and anomaly explanations, and an explanation rewritten by the LLMs. We construct datasets with 100, 500, 1000 and 2000 samples, with time series lengths of 180, 360, and 720. Although in real applications the total length of the time series can be quite long, we do not consider this due to the context window limitations of the LLMs. During instruction fine-tuning, the prompt we feed into LLaMA3 is the concatenation of the ideal explanation with the instruction prompt and the requirements prompt as described in Appendix A.3.