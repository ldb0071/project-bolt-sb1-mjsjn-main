Page 2

This debate raises a fundamental question: Do LLMs truly understand time series? To address this question, we must consider not only the models' predictive performance but also their ability to recognize normal patterns, identify abnormal behavior, and provide explanations for their decisions. This understanding requires a deeper understanding of the underlying temporal dynamics.

In this paper, we present the first comprehensive investigation into LLMs' understanding of time series data through the lens of anomaly detection. We focus on the behavior of state-of-the-art LLMs and multimodal LLMs (M-LLMs) across different anomaly types under controlled conditions. Our evaluation strategy incorporates multimodal inputs (textual and visual representations of time series), various prompting techniques, and structured output formats. The results are quantitatively assessed using the affinity F1 score to challenge unvalidated conjectures and claims about LLMs' time series understanding in prior works. This work leads to a more nuanced understanding of LLMs' capabilities and limitations in processing time series data.

We provide empirical evidence that contradicts several prevailing beliefs about LLMs' abilities in time series analysis, revealing:

- 路 Visual Advantage: LLMs perform significantly better when processing visualized time series data compared to textual representations.
- 路 Limited Reasoning: Contrary to expectations, LLMs do not extensively leverage complex reasoning processes when analyzing time series data. Their performance often decreases when prompted to explain their reasoning.
- 路 Non-Human-Like Processing: LLMs' approach to anomaly detection differs from human perception. They can identify subtle trends that humans might miss and their performance is not tied to arithmetic abilities.
- 路 Model-Specific Capabilities: Time series understanding and anomaly detection capabilities differ across various LLM architectures, highlighting the importance of model selection.

## 2 RELATED WORK

LLMs for Time Series Analysis. LLMs have been applied to various time series analysis tasks, including forecasting and classification. These models have shown promising results in capturing temporal dependencies and patterns in time series data. Gruver et al. (2023) demonstrated that LLMs like GPT-3 and LLaMA-2 can perform zero-shot time series forecasting by encoding time series as strings of numerical digits, achieving comparable performance to purpose-built models. Liu et al. (2024c) proposed a Cross-Modal LLM Fine-Tuning framework to address the distribution discrepancy between textual and temporal input tokens in LLM-based multivariate time series forecasting. Liu et al. (2024b) introduced Time-MMD, a multi-domain, multimodal time series dataset for LLM finetuning. For anomaly detection, Liu et al. (2024a) proposed AnomalyLLM, a knowledge distillation-based approach using GPT-2 as the teacher network. Zhang et al. (2024) provided a comprehensive survey of LLM applications in time series analysis. In the financial domain, Wimmer & Rekabsaz (2023) used vision language models, i.e., CLIP, but not M-LLMs to process image representations of stock data for market change prediction.

However, the effectiveness of LLMs for time series analysis remains controversial. Zeng et al. (2022) argued that the permutation-invariant nature of self-attention mechanisms may lead to loss of critical temporal information. Tan et al. (2024) found that removing the LLM component or replacing it with a basic attention layer often improved performance in popular LLM-based forecasting methods. The interpretability of LLMs in time series analysis remains a challenge, as their reasoning capabilities are often opaque and difficult to interpret.

Time Series Anomaly Detection. Time series anomaly detection is a critical task in various domains, including finance, healthcare, and cybersecurity. Traditional methods rely on statistical techniques, while recent work has focused on developing deep learning-based approaches (Audibert et al., 2022; Chen et al., 2022; Tuli et al., 2022). Audibert et al. (2022) compared conventional, machine learning-based, and deep neural network methods, finding that no family of methods consistently outperforms the others. Chen et al. (2022) proposed a deep variational graph convolutional recurrent network for multivariate time series anomaly detection. Tuli et al. (2022) introduced a transformer-based anomaly detection model with adversarial training and meta-learning.

However, recent studies have highlighted significant flaws in current time series anomaly detection benchmarks and evaluation practices (Wu & Keogh, 2021; Huet et al., 2022; Sarfraz et al., 2024). Wu & Keogh (2021) argued that popular benchmark datasets suffer from major flaws like triviality and mislabeling, potentially creating an illusion of progress in the field. Huet et al. (2022) pointed out that the classical F1 score fails to reflect approximate but non-overlapping detections, which are common in time series. Sarfraz et al. (2024) criticized the persistent use of flawed evaluation metrics and inconsistent benchmarking practices, suggesting that complex deep learning models may not offer significant improvements over simpler baselines in the semi-supervised setting.