# Page 16

## Page Information

- **Type**: table_page
- **Word Count**: 265
- **Has Tables**: False
- **Has Figures**: False

## Content

# Page 16

## A PARAMETER SENSITIVITY

100 100 100

100

100

100

We set the window size as 100 throughout the main text, which considers the temporal information, memory and computation efficiency. And we set the loss weight λ based on the convergence property of the training curve. 95 95 96 98 SMD MSL SMD MSL 96 98 95 96 98

Furthermore, Figure 7 provides the model performance under different choices of the window size and the loss weight. We present that our model is stable to the window size over extensive datasets (Figure 7 left). Note that a larger window size indicates a larger memory cost and a smaller sliding number. Especially, only considering the performance, its relationship to the window size can be determined by the data pattern. For example, our model performs better when the window size is 50 for the SMD dataset. Besides, we adopt the loss weight λ in Equation 5 to trade off the reconstruction loss and the association part. We find that λ is stable and easy to tune in the range of 2 to 4. The above results verify the sensitivity of our model, which is essential for applications. 1 2 3 4 5 6 factor 85 90 f-score SMD MSL SMAP SWaT PSM SMD MSL SMAP SWaT PSM 90 85 F-score 50 100 150 200 250 300 Window Size 1 2 3 4 5 6 factor 90 92 94 f-score SMAP SWaT PSM SMAP SWaT PSM 90 92 94 F-score 1 3 2 4 5 6 ! 85 90 90 94 92 F1-score (%) F1-score (%) 50 100 150 200 250 300 1 2 3 4 5 6 Window Size Loss Weight

<!-- image -->

Figure 7: Parameter sensitivity for sliding window size (left) and loss weight λ (right). The model with λ = 0 still adopts the association-based criterion but only supervised by reconstruction loss.

<!-- image -->

## Visual Content

### Page Preview

![Page 16](/projects/llms/images/2110.02642v5_page_16.png)
