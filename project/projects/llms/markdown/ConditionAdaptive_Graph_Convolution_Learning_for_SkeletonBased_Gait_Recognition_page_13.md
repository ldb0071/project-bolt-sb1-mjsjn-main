# Page 13

## Page Information

- **Type**: main_content
- **Word Count**: 62
- **Has Tables**: False
- **Has Figures**: True

## Content

# Page 13

## A. Datasets

CASIA-B. The CASIA-B [21] dataset contains 124 walking subjects, and each subject includes 110 sequences obtained from 11 camera views. For each view, each subject has 10 sequences of 3 walking conditions, i.e., 6 sequences of normal (NM) walking, 2 sequences of walking with a bag (BG), and 2 sequences of walking with a coat (CL). The training and testing settings followed the protocols reported in [60]. The sequences of the first 74 subjects were used for training, and the sequences of the remaining 50 subjects were used for testing. Specifically, in the testing phase, the NM sequences were used as gallery sets, and the BG and CL sequences were used as probe sets. The skeleton data were extracted by HRNet [32] and OpenPose [33]. Unless otherwise stated, the HRNet data were used on CASIA-B.

OU-MVLP. The OU-MVLP [11] dataset contains 10307 subjects, and each subject includes 28 sequences obtained from 14 camera views. For each view, each subject has 2 sequences (index '01' and index '02'). The training and testing followed the protocols reported in [11]. The sequences of the first 5153 subjects were used for training, and the sequences of the remaining 5154 subjects were used for testing. Specifically, in the testing phase, the sequences with index '01' were used as gallery sets, and the sequences with index '02' were used as probe sets. This dataset provides skeleton data estimated by AlphaPose [34] and OpenPose [33]. In this paper, we used skeleton data extracted by AlphaPose [34].

## Visual Content

### Page Preview

![Page 13](/projects/llms/images/ConditionAdaptive_Graph_Convolution_Learning_for_SkeletonBased_Gait_Recognition_page_13.png)

### Figures

![](/projects/llms/figures/ConditionAdaptive_Graph_Convolution_Learning_for_SkeletonBased_Gait_Recognition_page_13_figure_1.png)

