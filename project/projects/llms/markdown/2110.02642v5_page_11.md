# Page 11

## Page Information

- **Type**: main_content
- **Word Count**: 217
- **Has Tables**: False
- **Has Figures**: False

## Content

# Page 11

## 4.1 MAIN RESULTS

Real-world datasets We extensively evaluate our model on five real-world datasets with ten competitive baselines. As shown in Table 1, Anomaly Transformer achieves the consistent state-of-theart on all benchmarks. We observe that deep models that consider the temporal information outperform the general anomaly detection model, such as Deep-SVDD (Ruff et al., 2018) and DAGMM (Zong et al., 2018), which verifies the effectiveness of temporal modeling. Our proposed Anomaly Transformer goes beyond the point-wise representation learned by RNNs and models the more informative associations. The results in Table 1 are persuasive for the advantage of association learning in time series anomaly detection. In addition, we plot the ROC curve in Figure 3 for a complete comparison. Anomaly Transformer has the highest AUC values on all five datasets. It means that our model performs well in the false-positive and true-positive rates under various pre-selected thresholds, which is important for real-world applications. 75 75

NeurIPS-TS benchmark This benchmark is generated from well-designed rules proposed by Lai et al. (2021), which completely includes all types of anomalies, covering both the pointwise and pattern-wise anomalies. As shown in Figure 4, Anomaly Transformer can still achieve state-of-the-art performance. This verifies the effectiveness of our model on various anomalies.

Ablation study As shown in Table 2, we further investigate the effect of each part in our model. Our association-based criterion outperforms the widely-used reconstruction criterion consistently.

Figure 4: Results for NeurIPS-TS.

<!-- image -->

T

r

Specifically, the association-based criterion brings a remarkable 18.76% (76.20 → 94.96) averaged absolute F1-score promotion. Also, directly taking the association discrepancy as the criterion still achieves a good performance (F1-score: 91.55%) and surpasses the previous state-of-the-art model

THOC (F1-score: 88.01% calculated from Table 1). Besides, the learnable prior-association (corresponding to σ in Equation 2) and the minimax strategy can further improve our model and get 8.43% (79.05 → 87.48) and 7.48% (87.48 → 94.96) averaged absolute promotions respectively. Finally, our proposed Anomaly Transformer surpasses the pure Transformer by 18.34% (76.62 → 94.96) absolute improvement. These verify that each module of our design is effective and necessary. More ablations of association discrepancy can be found in Appendix D.

Table 2: Ablation results (F1-score) in anomaly criterion, prior-association and optimization strategy. Recon , AssDis and Assoc mean the pure reconstruction performance, pure association discrepancy and our proposed association-based criterion respectively. Fix is to fix Learnable scale parameter σ of prior-association as 1.0. Max and Minimax ref to the strategies for association discrepancy in the maximization (Equation 4) and minimax (Equation 5) way respectively.

| Architecture   | Anomaly Criterion   | Prior- Association   | Optimization Strategy   |   SMD |   MSL |   SMAP |   SWaT |   PSM |   Avg F1 (as %) |
|----------------|---------------------|----------------------|-------------------------|-------|-------|--------|--------|-------|-----------------|
| Transformer    | Recon               | ×                    | ×                       | 79.72 | 76.64 |  73.74 |  74.56 | 78.43 |           76.62 |
|                | Recon               | Learnable            | Minmax                  | 71.35 | 78.61 |  69.12 |  81.53 | 80.4  |           76.2  |
| Anomaly        | AssDis              | Learnable            | Minmax                  | 87.57 | 90.5  |  90.98 |  93.21 | 95.47 |           91.55 |
| Transformer    | Assoc               | Fix                  | Max                     | 83.95 | 82.17 |  70.65 |  79.46 | 79.04 |           79.05 |
|                | Assoc               | Learnable            | Max                     | 88.88 | 85.2  |  87.84 |  81.65 | 93.83 |           87.48 |
| *final         | Assoc               | Learnable            | Minmax                  | 92.33 | 93.59 |  96.9  |  94.07 | 97.89 |           94.96 |

## Visual Content

### Page Preview

![Page 11](/projects/llms/images/2110.02642v5_page_11.png)
