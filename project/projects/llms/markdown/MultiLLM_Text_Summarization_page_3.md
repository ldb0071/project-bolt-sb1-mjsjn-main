# Page 3

## Page Information

- **Type**: figure_page
- **Word Count**: 291
- **Has Tables**: False
- **Has Figures**: True

## Content

# Page 3

## 1 Introduction

Large language models (LLMs) have been shown to have the potential to produce high-quality summaries (Chowdhery et al., 2022; Zhang et al., 2023; Goyal et al., 2023; Pu et al., 2023b). However, despite the remarkable progress in LLM-based summarization, limitations still exist for long documents where useful information is abundant but sparsely distributed throughout the text. Research by (Liu et al., 2023) highlights that a naive application of LLMs may overlook critical details or fail to grasp the holistic meaning of a document, indicating the need for more refined methods.

To address this, recent efforts have explored prompt-engineering techniques to guide LLMs towards producing better summaries (Adams et al., 2023). These techniques, while promising, still face limitations in consistently delivering high-

quality summaries across different document types and structures. Instead of relying solely on a single model or simple prompt-engineering methods, we propose an approach novel to the summarization domain that focuses on aggregating the collective strengths of multiple LLMs. By combining the capabilities of multiple models with a diverse set of knowledge bases, we show it's possible to achieve more robust summaries across domains.

Summary of Main Contributions. The main contributions of this work are as follows:

- · We propose the first framework for multiLLM text summarization and investigate two topologies: centralized and decentralized.
- · We find that multi-LLM text summarization often performs better than using a single LLM for summarization.
- · We conduct experiments on how prompting, number of LLMs, and various combinations of generating and evaluating LLMs can affect quality of summaries in the multi-LLM setup.

## Visual Content

### Page Preview

![Page 3](/projects/llms/images/MultiLLM_Text_Summarization_page_3.png)

### Figures

![](/projects/llms/figures/MultiLLM_Text_Summarization_page_3_figure_1.png)


![](/projects/llms/figures/MultiLLM_Text_Summarization_page_3_figure_2.png)

