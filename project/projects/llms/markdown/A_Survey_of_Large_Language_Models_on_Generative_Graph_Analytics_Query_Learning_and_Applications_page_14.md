# Page 14

## Page Information

- **Type**: figure_page
- **Word Count**: 443
- **Has Tables**: True
- **Has Figures**: True

## Content

# Page 14

## Prompt III-4: Self-prompting

Instructor: You are a brilliant graph master that can handle anything related to graphs like retrieval, detection and classification.

Graph description language: GML, GraphML as shown in Section II-D.

Context: Node P357 has 4 neighbors, where each of which are about anomaly detection with statistical models...

Query: What is the clustering coefficient of node P357?

Aminer [57] datasets and finds that:

- · The design of prompts significantly impacts the results. The choice of graph description language, the organization of input data, and the position of in-context knowledge, such as questions, statements, and examples, all affect the model's ability to understand the graph structure.
- · Role prompting techniques can improve the effectiveness of LLMs by guiding the model to view the graph as roles and relationships between roles in a specific context. Providing LLMs with more semantic information leads to more accurate results.
- · Examples in prompts have mixed impacts on graph structure understanding. Adding examples in prompts to guide LLMs in understanding graph structures may not necessarily improve the results; in some graph structure learning tasks, examples may introduce noise.

API call prompts LLMs exhibit limited ability to perform precise mathematical calculations, multi-step logical reasoning, spatial topological structuring, and temporal information processing. To bridge these gaps, taking inspiration from recent models such as ChatGPT and Toolformer [58], GraphToolFormer [59] is proposed to equip LLMs with graph reasoning capabilities by training them over a prompt dataset that contains graph reasoning API annotated by ChatGPT. These graph reasoning APIs are used to call external reasoning tools. Then, the trained LLMs can solve graph tasks, from loading graph data and inferring graph attributes to graph partition tasks.

The framework consists of three parts. First, it generates a prompt dataset by providing ChatGPT with a regular prompt, guiding ChatGPT to add an API call to the original prompt, and then creating a prompt with an API call.

## Visual Content

### Page Preview

![Page 14](/projects/llms/images/A_Survey_of_Large_Language_Models_on_Generative_Graph_Analytics_Query_Learning_and_Applications_page_14.png)

### Figures

![](/projects/llms/figures/A_Survey_of_Large_Language_Models_on_Generative_Graph_Analytics_Query_Learning_and_Applications_page_14_figure_1.png)


## Tables

### Table 1

|  |
| --- |
|  |

### Table 2

|  |
| --- |
|  |

### Table 3

|  |
| --- |
|  |

### Table 4

|  |
| --- |
|  |

### Table 5

|  |
| --- |
|  |

### Table 6

|  |
| --- |
|  |

### Table 7

|  |
| --- |
|  |

### Table 8

|  |
| --- |
|  |

### Table 9

|  |
| --- |
|  |

### Table 10

|  |
| --- |
|  |

### Table 11

|  |
| --- |
|  |

### Table 12

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
