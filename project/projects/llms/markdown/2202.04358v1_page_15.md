# Page 15

## Page Information

- **Type**: figure_page
- **Word Count**: 464
- **Has Tables**: False
- **Has Figures**: True

## Content

# Page 15

## 4.1 Comparison of Prediction Performace of House Price Valuation Models

The relative error rate of each prediction is calculated on the validation set and test set, which can be plotted as the following scatter plot in Figure 6. Among them, the feature directions of the point cloud can be found according to the method of principal component analysis (PCA), and are plotted on the graph using black dashed lines. It should be noted that we use the same range of axes when plotting the point cloud in order to make the comparison clearer, and there are no more than 5% of points outside this range that are not shown.

It is not difficult to find that GWR and GNNWR have great superiority over the OLS models. The point set is densely distributed close to the yaxis, indicating that most of the locations that cannot be well predicted by OLS can be more effectively and accurately predicted by spatial statistical models. The idea of local linear regression can effectively reduce the prediction error. Comparing GWR with GNNWR, we can find that the feature direction lies above y=x, i.e. GNNWR can reduce the prediction error of GWR model at the same location by a certain proportion.

Further, we compare the two models by a Q-Q plot and a histogram chart as Figure 7, which are plotted by Matlab.

<!-- image -->

<!-- image -->

<!-- image -->

(b) GNNWR-OLS

Figure 6: Point Clouds and Feature Directions of Error Rates

<!-- image -->

(a) On Merged Validation Set

Figure 7: Q-Q Plots of Relative Error Rates

<!-- image -->

Again, no more than 5% of the points are not shown outside this range. Ordering the relative error rates, it can be found that the relationship between the k th value on the validation set is approximately δ ( k ) GWR = 1 . 123 δ ( k ) GNNWR +0 . 0033 . The relationship between the k th value on the test set is approximately δ ( k ) GWR = 1 . 160 δ ( k ) GNNWR + 0 . 0003 . These reference lines that represent the theoretical distribution have a clear deviation with y = x , which enable us to confirm the superiority of GNNWR models.

A comparison of the histograms as Figure 8 still gives clear results. On the validation set, taking the histogram horizontal coordinates between [0,1] and bin width of 0.09, it can be found that 9 of the 11 bins with error rate less than or equal to 9.9% have more data from GNNWR model.This trend is also ev-

ident in the test set. Setting the histogram horizontal coordinates between [0, 1] and bin width taking 0.15, similarly it can be found that five of the seven bins with error rate less than or equal to 10.5% have more data from the GNNWR model.

<!-- image -->

(a) On Merged Validation Set

Figure 8: Histograms of Relative Error Rates

<!-- image -->

Besides, we can combine the prediction data of validation set from both models as Figure 9. The numbers of data in both sets which are below certain value can be calculated, and the ratio of two numbers can be plotted as blue line on the graph. The ratio of the number of predicted data from GWR to the number of data from GNNWR when the statistical error rate is above a certain value can be plotted as the orange line on the graph. For all data (two times of predictions on 2440 records) with a relative error rate of less than 0.203, the predictions from GNNWRare 1.34 times higher than those from GWR. In contrast, among all data with error rates higher than 0.37, the predictions from GWR are as much as 1.62

times higher than those from GNNWR. In conclusion, the predictions from GNNWR account for more of the high-precision predictions and the predictions from GWR account for more of the high-error predictions.

Figure 9: The Ratio of the Top N Best/Worst Predictions from 2 Models

<!-- image -->

Comparing with other literature, it can be found that another study also supports the conclusion that GWR can significantly reduce the prediction error compared to OLS models, indicating that spatial heterogeneity exists. In another study on Shenzhen house prices, the authors used the GWR model to increase the R 2 from 0.56 to 0.79. [12] Some simple AI models, such as decision tree models, can even predict worse than OLS if they are not designed properly. [31] In a separate study comparing the OLS model with multiple models, the best Stepwise and tuned SVM model reduced the RMSE by 25%, the polynomial regression model reduced the RMSE by 8.3%, and even the optimal simple neural network selected from the 1-3 hidden layers increased the RMSE by 66%. [26] Since the 1990s, scholars have been trying to use ordinary neural network models to predict house prices and compare them with OLS models. Some studies have demonstrated the superiority of the neural network approach, but others have found that there is no great need to use neural networks. Considering the 47% reduction in RMSE metrics compared to OLS in this study, it is easy to see that simply using complex functions trained by neural networks to approximate the training data set does not improve the prediction accuracy, and that a GWR-based framework can best capture information on the geographic distribution. These indicate that accurate estimation of spatial heterogeneity is extremely necessary.

## Visual Content

### Page Preview

![Page 15](/projects/llms/images/2202.04358v1_page_15.png)

### Figures

![](/projects/llms/figures/2202.04358v1_page_15_figure_1.png)

