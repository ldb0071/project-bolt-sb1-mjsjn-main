# Page 12

## Page Information

- **Type**: figure_page
- **Word Count**: 381
- **Has Tables**: True
- **Has Figures**: False

## Content

# Page 12

## 3.2 Comparison of Indicators of House Price Valuation Models

The evaluation of the house price valuation model examines both the ability to fit on the training set and to predict on the test set. We stochastically divides 2871 house price records into the train set and validation set with 2440 records as 10 folds, and 431 records remnant working as the test set.

We evaluated all parameters of the model using parameters such as coefficient of R 2 , RMSE, MAE, MAPE, AICc and Pearson correlation coefficient. For the dataset generated after the 10-fold crossover, the validation sets are merged and the following results are obtained.

Clearly, these data confirm the greatness of the GNNWR model. The worst prediction comes from the OLS model, which has the lowest R 2 and the highest prediction error measured by RMSE, MAE and MAPE. Because of the severe spatial non-stationarity, the OLS model is difficult to detect the intrinsic relations and spatial fluctuations between house price and other independent variables. Compared with GWR model, the RMSE of GNNWR model declines about 13.0%, and the MAE of GNNWR model declines about 13.5%. Other indicators, like R2 and MAPE, also make the superiority of GNNWR model clear. Additionally, the mean residual error of GNNWRmodel is much lower than GWR model ' s with a 62.2% reduction, which means that the prediction of GNNWR model has a greater unbiasedness than GWR's on this dataset. In short, we can deduce that the GNNWR model gains a notable progress on the generalization ability.

To be more specific, we can compare the indica-

Table 3: Exploratory Analysis and Descriptive Statistics of the Experimental Dataset

| Indicator               | Price   |     AB |        NPS |     MF |    GR |     PR |        SD |   QAPS |   NSS |       DSS |
|-------------------------|---------|--------|------------|--------|-------|--------|-----------|--------|-------|-----------|
| Mean                    | 62219.3 | 17.995 |  507.196   |  2.625 | 0.34  | 3.113  |  6586.1   | 3.704  | 1.769 |   930.5   |
| Maximum                 | 132000  | 51     | 5500       | 36.6   | 0.99  | 7      | 24967.2   | 4.5    | 8     | 25110     |
| Minimum                 | 16100   |  1     |    1       |  0     | 0.1   | 0.1    |    23.2   | 0      | 0     |    16.8   |
| Std. Dev.               | 22986.5 |  7.138 |  647.509   |  1.888 | 0.13  | 1.438  |  4933.7   | 1.179  | 1.432 |  1838.5   |
| Correlation Coefficient | -       | -0.118 |    0.079   |  0.262 | 0.216 | 0.105  |    -0.504 | 0.08   | 0.248 |    -0.236 |
| Variation Coefficient   | 2.707   |  2.521 |    0.783   |  1.391 | 2.62  | 2.164  |     0.749 | 3.143  | 1.235 |     0.506 |
| VIF                     | -       |  1.622 |    1.243   |  1.227 | 1.122 | 1.15   |     1.167 | 1.204  | 1.365 |     1.136 |
| t-test p                | -       |  0     |    3.4e-08 |  0     | 0     | 0.0197 |     0     | 0.3208 | 0     |     0     |

Table 4: Indicators of GNNWR, GWR and OLS on Merged Validation Set

| Model   |       R2 |     RMSE |      MAE |     MAPE |   Mean Err. |   Pearson Cor. Coe. |
|---------|----------|----------|----------|----------|-------------|---------------------|
| GNNWR   | 0.840177 |  9069.56 |  6558.63 | 0.111965 |    27.8881  |            0.916637 |
| GWR     | 0.788728 | 10427.7  |  7581.75 | 0.128538 |   -73.9177  |            0.888123 |
| OLS     | 0.432101 | 17096.3  | 13003.8  | 0.228767 |    -5.60228 |            0.657404 |

tors of the GWR and the GNNWR models in each process of modeling on 10 train sets. There parameters reflect the fitting quality of modeling process. In Table 5, the Train set of 0 means that data set 0 is excluded and the 1, 2, ..., 9 data sets are selected, and so on.

It should be noted that the number after GWR refers to the number of most suitable neighboring elements selected based on the AICc value. Since the training set is slightly different, the most appropriate number of neighboring elements is re-picked each time the GWR model is built.

For all of these 10 data sets, GNNWR models have completely beaten GWR models no matter we utilize AICc, RMSE, R2 or Pearson correlation coefficient as a judge. The evident advantage on AICc reveals that the GNNWR model not only provides a better prediction about house price, but also applies a more accurate space weight matrix without much more complexity. In contrast, the GWR model has to face the overfitting problem, which makes the correctness of the predictions on the validation sets slump. To sum up, the GNNWR model producing a more capable kernel function than any GWR models, performs most outstandingly in catching spatial heterogeneity details, estimating spatial weight and predicting dependent variables.

Furthermore, we can judge the generalization ability by predicting the test set. In this study, we use the models with the best generalization ability to compare. Both of the GNNWR and the GWR models perform best when we opt the validation set as dataset 4, and the other indicators are shown in the next Table 6.

Compared with the GWR model, the GNNWR model has an explicit superiority about predicting the test dataset. The MAE slumps 10.2% and the MAPE descents 10.7%, which are practical for real

estate agency to have a better estimation. The RMSE reduces 6.6%, the R2 and the Pearson correlation coefficient has improved as well and the mean error has increased.

## Visual Content

### Page Preview

![Page 12](/projects/llms/images/2202.04358v1_page_12.png)

## Tables

### Table 1

| Model | Variable | Intercept | AB | NPS | MF | SD | GR | PR | QAPS | NSS | DSS |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Best
Fitting
Model | F Value | 614.58 | 234.48 | 381.14 | 562.52 | 537.77 | 503.31 | 385.10 | 418.17 | 646.79 | 502.37 |
| None | γ
1 | 0.0198 | 0.0893 | 0.4068 | 0.4108 | 0.4200 | 0.4560 | 0.5951 | 0.6102 | 0.6753 | 0.6692 |
| None | γ
2 | 0.0004 | 0.0057 | 0.1095 | 0.1085 | 0.1108 | 0.1120 | 0.1629 | 0.1595 | 0.1789 | 0.1824 |
| None | Significant
Level | 1E-10 | 1E-08 | 1E-09 | 1E-10 | 1E-10 | 1E-10 | 1E-10 | 1E-11 | 1E-12 | 1E-11 |
| Worst
Fitting
Model | F2 | 1017.10 | 471.84 | 573.85 | 872.23 | 845.57 | 774.72 | 344.85 | 367.06 | 560.84 | 432.05 |
| None | γ
1 | 0.0289 | 0.1302 | 0.5264 | 0.5279 | 0.5338 | 0.5990 | 1.3826 | 1.3973 | 1.5010 | 1.4639 |
| None | γ
2 | 0.0008 | 0.0115 | 0.1760 | 0.1741 | 0.1758 | 0.1807 | 0.9202 | 0.9138 | 0.9341 | 0.8760 |
| None | Significant
Level | 0 | 1E-04 | 1E-04 | 1E-05 | 1E-05 | 1E-05 | 1E-04 | 1E-04 | 1E-04 | 1E-04 |
