# Page 6

## Page Information

- **Type**: figure_page
- **Word Count**: 406
- **Has Tables**: False
- **Has Figures**: False

## Content

# Page 6

## C. Large Language Models

Currently, there is no precise definition for Large Language Models (LLMs). However, according to the pioneering surveys [47] [48] on LLMs, a distinction can be made between LLMs and Pre-trained Language Models (PLMs). LLMs are large language models with billion-level parameters that are pretrained on massive amounts of data, such as Llama [5] and ChatGPT. Conversely, PLMs are pre-trained language models with million-level parameters that can be more easily finetuned on task-specific data. While LLMs and PLMs share similarities in their pre-training process, the former is characterized by its larger size and ability to generate human-like text. Thus, it is essential to consider the potential implications of using LLMs in various applications.

## Visual Content

### Page Preview

![Page 6](/projects/llms/images/A_Survey_of_Large_Language_Models_on_Generative_Graph_Analytics_Query_Learning_and_Applications_page_6.png)
