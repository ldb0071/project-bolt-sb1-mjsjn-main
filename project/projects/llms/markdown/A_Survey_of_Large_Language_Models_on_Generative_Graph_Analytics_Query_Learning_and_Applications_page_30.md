# Page 30

## Page Information

- **Type**: citation_rich
- **Word Count**: 936
- **Has Tables**: False
- **Has Figures**: False

## Content

# Page 30

## B. Graph-formed Reasoning Methods

The graph form, with its inherent structural features, not only mimics human reasoning patterns but also validates answers from LLM through the relationships between nodes and local structure. Existing work can roughly be divided into two categories: think on the graph and verify on the graph , as shown in Figure 18. Think on the graph refers to LLM thinking in the form of a graph, where each node on the graph represents a step in the thinking process or

an intermediate conclusion during thinking, and the edges on the graph indicate the direction of LLM inference or the relationships between intermediate thinking steps. In this way, the LLM thinking process can be visually represented in graph form. Verify on the graph means verifying the consistency and correctness of answers by utilizing the graph's structure. For example, if the end node of different paths is the same, the results derived from different paths should be the same. If contradictory conclusions arise, then the obtained conclusion is incorrect.

- 1) Think on the graph : The GoT* reasoning method [36] is proposed with a two-stage framework to enable LLM to reason on a graph for answering multiple-choice questions. Initially, the input query is converted into a graph form, and with the incorporation of graph and multimodal features, LLM generates rationale. This rationale updates the graph to a graph with rationales, which is then combined with the original input and fed into the decoder to obtain the final answer.

However, GoT* allows LLM to enhance the graph using multimodal information but does not reason step-bystep deduction in graph form. The Graph of Thought (GoT) [34] represents LLM's intermediate thinking as an arbitrary graph, facilitating powerful prompting for solving algorithmic problems like sorting and keyword counts. LLM thoughts are depicted as vertices in this approach, with edges representing dependencies between them. By continuously adding LLM responses to the graph, arbitrary thoughts can be aggregated, forming a directed acyclic graph.

Multiple LLMs can also be collaboratively harnessed to tackle complex mathematical challenges, extending beyond the capabilities of a single LLM. Cumulative Reasoning (CR) [35] is proposed as a more human-like reasoning process. CR utilizes three LLMs in different roles: the proposer, verifier, and reporter. The proposer suggests the next step, the verifier checks the accuracy of the steps, and the reporter decides when the reasoning process should end. Three roles of LLMs collaborate to achieve more accurate reasoning processes.

TABLE IV: Prompts for Graph-formed Reasoning.

| Task                                                                  | Prompts                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|-----------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Sorting < Instruction > additional text. < /Instruction >< Examples > | Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no like Input: [5, 1, 0, 1, 2, 0, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7] Output: [0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9] < /Examples > Input: [input list]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| Set Operations                                                        | < Instruction > Find the intersection of two sets of numbers. Output only the set of numbers that are present in both sets, no additional text. < /Instruction >< Examples > like Input Set 1: [13, 16, 30, 6, 21, 7, 31, 15, 11, 1, 24, 10, 9, 3, 20, 8] Input Set 2: [25, 24, 10, 4, 27, 0, 14, 12, 8, 2, 29, 20, 17, 19, 26, 23] Output: [24, 10, 20, 8] < /Examples > Input Set 1: set1 Input Set 2: set2                                                                                                                                                                                                                                                                                                                                                                                                                 |
| Keyword Counting                                                      | < Instruction > Count the frequency of how many times each country is explicitly named in the input text. You can generate any intermediate lists and states, but the final output should only contain the frequency of each country that appears at least once in the following json format, prefixed with 'Output: ' (make sure to keep the same spelling for each country in the output as in the input text): {{ 'country1': frequency1, 'country2': frequency2, ... }} < /Instruction >< Approach > To count the frequency for each country follow these steps: 1. Split the input passage into four paragraphs of similar length. 2. Count the frequency of each country in each paragraph. 3. Combine the frequencies of each country from each paragraph by adding them together. < /Approach >< Examples > (Omitted) |
| Document Merging                                                      | Merge the following 4 NDA documents < Doc1 > - < Doc4 > into a single NDA, maximizing retained information and minimizing redundancy. Output only the created NDA between the tags < Merged > and < /Merged > , without                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| Math word problems                                                    | Q: Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| Multi-hop Question Answering                                          | Question triplets: ('Hypocrite', directed by, $1), ($1, death date, $2) Question: When did the director of film Hypocrite (Film) die? To answer this question, we answer the following subquestions: (1) Who directed Hypocrite (Film)? The film Hypocrite was directed by Miguel Morayta. (2) When did Miguel Morayta die? Miguel Morayta died on 19 June 2013. So the answer is 19 June 2013.                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Logic reasoning                                                       | · Premises: 1. It is not true that some giant language models do not have good performance. 2. All language models with good performance are used by some researchers. 3. If a language model is used by some researchers, it is popular. 4. If BERT is a giant language model, then GPT-3 is also a giant language model. 5. BERT is a giant language model. · Hypothesis: GPT-3 is popular. · Label: [True]                                                                                                                                                                                                                                                                                                                                                                                                                 |

2) Verify on the graph : Verify on the graph is to validate the intermediate reasoning results of LLM to enhance its performance. The Reasoning Graph Verifier (RGV) [83] in this study assumes a logical connection between the intermediate steps of different inference paths created by LLM. This allows the multiple solutions generated by LLM for a reasoning task to be structured into a reasoning graph, aiming to improve the accuracy and reliability of the outcomes. By constructing reasoning graphs from the various solutions provided by LLM, a verifier is trained to determine the correctness of the resulting reasoning graph. During the prediction phase, RGV assesses the solutions and selects the highest-scoring one as the final answer.

However, this work trains an extra model to determine whether the graph formed by the solutions generated by LLM is correct rather than utilizing the knowledge within the graph and the relationships between the knowledge for validation. The Graph-guided CoT [84] approach aims to improve the relevance of rationales generated by CoT during multi-step reasoning. It starts by extracting triplets from questions using LLM to build a question graph and generates intermediate subquestions from this graph. To ensure the rationale from LLM is logical, Retrieval Augmented Generation (RAG) is used. In an open-book scenario, knowledge retrieval is based on the sub-

questions, providing retrieved documents and sub-questions as input to LLMs. LLMs generate rationales for the subquestions, creating a rationale graph. Based on the rationale graph, the study assesses whether the generated rationales aid in solving the original question. By iteratively generating intermediate rationales, the solution to the original question can be determined.

Finally, we provide manual prompt examples for various graph learning tasks in Table IV. Additionally, we test LLMs with GPT-4 for sorting and logic reasoning using manual prompts, as shown in Figure 19.

## Visual Content

### Page Preview

![Page 30](/projects/llms/images/A_Survey_of_Large_Language_Models_on_Generative_Graph_Analytics_Query_Learning_and_Applications_page_30.png)
