Page 15

Output : Output UI is (partially) implemented by the LLM. E.g., in TruckPlatoon , the output generated by the LLM component can replace a data cockpit with gauges and other visuals displaying numerical data.

Both : Input and output UI are (partially) implemented by the LLM. E.g., in MyCrunchGpt , the DesignAssistant provides a convenient conversational interface for parameterization of APIs and

tools and feedback on missing values, which otherwise might require a complex GUI.

Logic indicates whether the LLM component determines the control flow of the application. It discerns two characteristics:

cAlculate : The output does not significantly impact the control flow of the application, i.e., the output is processed like data. E.g., MyCrunchGpt SettingsEditor modifies a JSON file, replacing a programmed function; MyCrunchGpt DesignAssistant asks the user for parameters, but the sequence of calling APIs and tools follows a predefined workflow; the workflow computed by LowCode Planning is displayed without influencing the application's control flow.

Control : The output of the LLM is used for controlling the application. E.g., the plans generated by MatrixProduction Manager serve to schedule and activate production modules; the actions proposed by AutoDroid TaskExecutor are actually executed and determine how the control flow of the app proceeds.

Since an LLM invocation always computes a result, cAlculate is interpreted as 'calculate only', making cAlculate and Control mutually exclusive.

Data addresses whether the LLM contributes to reading or writing persistent data:

none : The LLM does not contribute to reading or writing persistent data. This characteristic applies to most sample instances.