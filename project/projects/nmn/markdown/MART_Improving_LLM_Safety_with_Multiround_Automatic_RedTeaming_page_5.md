# Page 5

## Page Information

- **Type**: table_page
- **Word Count**: 429
- **Has Tables**: False
- **Has Figures**: False

## Content

# Page 5

## 2 Approach

In this section, we dive deeper into multi-round automatic red-teaming. We first discuss the general instruction fine-tuning and safety-focused seed data that we initialize the model with to provide a foundation for further safety tuning. Next, we describe how we develop an adversarial LLM M adv by optimizing it to generate new adversarial prompts at each iteration. Then, we discuss how to use self-supervised fine-tuning to improve the target model M tgt . Finally, as the target model continues to improve over its vulnerabilities, we demonstrate how to consistently find new adversarial prompts by optimizing both models in an iterative manner. We illustrate the general workflow of MART in Algorithms 1 and 2.

## Visual Content

### Page Preview

![Page 5](/projects/nmn/images/MART_Improving_LLM_Safety_with_Multiround_Automatic_RedTeaming_page_5.png)
