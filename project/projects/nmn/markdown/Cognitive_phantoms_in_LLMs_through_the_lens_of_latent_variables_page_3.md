# Page 3

## Page Information

- **Type**: citation_rich
- **Word Count**: 159
- **Has Tables**: False
- **Has Figures**: False

## Content

# Page 3

## Abstract

Large language models (LLMs) increasingly reach real-world applications, necessitating a better understanding of their behaviour. Their size and complexity complicate traditional assessment methods, causing the emergence of alternative approaches inspired by the field of psychology. Recent studies administering psychometric questionnaires to LLMs report humanlike traits in LLMs, potentially influencing LLM behaviour. However, this approach suffers from a validity problem: it presupposes that these traits exist in LLMs and that they are measurable with tools designed for humans. Typical procedures rarely acknowledge the validity problem in LLMs, comparing and interpreting average LLM scores. This study investigates this problem by comparing latent structures of personality between humans and three LLMs using two validated personality questionnaires. Findings suggest that questionnaires designed for humans do not validly measure similar constructs in LLMs, and that these constructs may not exist in LLMs at all, highlighting the need for psychometric analyses of LLM responses to avoid chasing cognitive phantoms.

Keywords: large language models, psychometrics, machine behaviour, latent vari- able modeling, validity

## Visual Content

### Page Preview

![Page 3](/projects/nmn/images/Cognitive_phantoms_in_LLMs_through_the_lens_of_latent_variables_page_3.png)
