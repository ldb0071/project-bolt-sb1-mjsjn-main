# Page 6

## Page Information

- **Type**: figure_page
- **Word Count**: 344
- **Has Tables**: True
- **Has Figures**: False

## Content

# Page 6

## 2.2 Evaluation of LLMs in Human Behavior Simulation

Simulation of human behavior requires the LLMs to faithfully embody assigned roles and identities and proactively interact with others (Wooldridge and Jennings, 1995; Franklin and Graesser, 1996; Ortony et al., 2003). See et al. (2019); Fang et al. (2023); Choi et al. (2023) propose evaluation frameworks toward LLMs' capabilities of natural lan-

guage understanding and generation. Rao et al. (2023); Jiang et al. (2023); Huang et al. (2023) evaluate LLMs' abilities to understand and maintain personality traits. Aher et al. (2023) introduce the Turing Experiment to evaluate whether LLMs can simulate the behavior of a representative sample of participants in human subject research. Park et al. (2023) propose a sandbox and an online social network to evaluate agents' social interactions. However, to the best of our knowledge, no systematic and fine-grained benchmark exists to assess the LLMs' believability. Hence, we aim to bridge this gap by constructing SimulateBench.

## Visual Content

### Page Preview

![Page 6](/projects/nmn/images/How_Far_Are_LLMs_from_Believable_AI_A_Benchmark_for_Evaluating_the_Believability_of_Human_Behavior_S_page_6.png)

## Tables

### Table 1

|  |
| --- |
|  |
|  |
|  |
| 0 |
|  |
|  |
|  |
| 0 |
|  |

### Table 2

| 0 |
| --- |
|  |
| 0 |
|  |
| 0 |
|  |
| 0 |
|  |
|  |
|  |

### Table 3

| 0 |
| --- |
|  |
|  |
|  |

### Table 4

|  |
| --- |
|  |
|  |
|  |
|  |
|  |
|  |
|  |
| 0 |
|  |

### Table 5

|  |
| --- |
|  |
|  |
|  |
|  |
|  |
|  |
|  |
|  |
|  |

### Table 6

|  |
| --- |
|  |
| 0.0 |
|  |
|  |
|  |
|  |
|  |
|  |
|  |

### Table 7

|  |
| --- |
|  |
|  |
|  |
|  |
|  |
|  |
|  |
|  |
|  |

### Table 8

|  |
| --- |
| 0 |
|  |
|  |
|  |
|  |
| 0 |
| 0 |
|  |
|  |

### Table 9

|  |
| --- |
|  |
|  |
|  |
|  |
|  |
|  |
|  |
|  |
|  |
