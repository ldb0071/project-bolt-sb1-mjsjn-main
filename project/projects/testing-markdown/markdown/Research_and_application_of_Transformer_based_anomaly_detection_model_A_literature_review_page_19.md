Page 19

Yu et al. [79] used ViT and ResNet as feature extractors to extract global features and local patches. Then, the extracted features are passed through the FastFlow model proposed in this paper for anomaly detection and anomaly location. The essence of FastFlow is to construct a bijective invertible mapping that projects image features into hidden vectors. To preserve the spatial positional relationship within the feature map and prevent the flattening and compression of visual features from a twodimensional space into a one-dimensional space, which could lead to the loss of crucial information, FastFlow incorporates a subnet equipped with a two-dimensional convolution layer in its flow model. This ensures that the corresponding spatial information is retained effectively. Stanislav et al. [36] experimentally demonstrated on CIFAR-100, and CIFAR-10 datasets that the pre-trained ViT can achieve excellent performance in near OOD tasks. They also pointed out that pre-trained ViT is robust to input disturbances.

Wrust et al. [80] investigated the application of ViT in the novelty detection of traffic scenario infrastructure. They performed fine-tuning on the output of Vanilla ViT by transforming it from predictive class labels to latent representations. Additionally, they employed ViT within a triplet loss-based Autoencoder framework, generating latent representations for input road infrastructure images using ViT. Through metric learning, they aimed to move the latent representations of negative examples away from the baseline and closer to the latent representations of positive samples. They applied this model structure to many existing Novelty detection methods, such as Local Outlier Factor (LOF), Isolated Forest, Angle-based Outlier Detection, One-class Support Vector Machine (OCSVM), and UMAP-based Local Entropy Factor, with good experimental results. The UNETR model used by Park et al. [62] is essentially a 3D UNET model, in which the encoder part uses the ViT structure. They converted the input images into sequence representations and connected them to the decoder utilizing a skip-connection structure.

TSViT [81] is an improved ViT model for time series tasks. They performed the anomaly detection task for the video tracking problem by encoding frames with only pedestrian position information into the embedded token and passing the spatial information of the pedestrian to TSViT. The author classified the detection features of TSViT into low-level features (3D gradient features, optical flow multi-scale histograms, structural context descriptors, and dynamic texture blending) and highlevel features (object trajectory features, object appearance features). ViTALnet [82] first employs ViT to extract local discriminatory features as feature representations. Subsequently, it introduces an anomaly estimation module that integrates global attention and a pyramidal architecture to enhance contextual information for fine-grained anomaly localization. VT-ADL [45], on the other hand, applies ViT to encode the

input image that has been subdivided into small pieces, and subsequently feeds the ViT-encoded image to the decoder for image reconstruction, forcing the network to learn the features representing the normal image, thus performs the image anomaly detection task in a reconstruction manner. VT-ADL additionally introduces a Gaussian mixture density function for the pixel-level image anomaly location. Gaussian mixture density function models the distribution of ViT-encoded features to estimate the distribution of normal data in the potential space. To achieve this goal, VT-ADL slightly modifies the structure of ViT by discarding the dropout layer in the network, which would lead to the instability of the Gaussian approximation network, and adds a MLP layer, which is a linear layer containing two GELU activation functions. Thus, VT-ADL can simultaneously perform image anomaly detection and anomaly location tasks from different fine-grained levels.

Fan et al. [83, 84] introduced a contrastive learning paradigm for ViT, using ViT as a feature extractor and performing image anomaly detection step-by-step through a contrast learning framework to mitigate the catastrophic forgetting problem. Lin et al. [85] utilized ViT-S self-supervised learning to reconstruct unlabeled pavement images. They proposed an encoding-retrieval-matching pavement anomaly detection method to address the classification retraining problem. De Nardin et al. [86] adopted a masked multi-head self-attention mechanism that allows the model to learn a relationship between different patches of the input images. They modified the architecture of ViT to achieve high-precision image anomaly detection by adding a new masking component and calculating attention between patches of different shapes. Lee et al. [87] utilized the ViT model to perform video anomaly detection tasks from the spatio-temporal context perspective. They focused on 3 different contextual prediction streams: masked, whole, and partial.