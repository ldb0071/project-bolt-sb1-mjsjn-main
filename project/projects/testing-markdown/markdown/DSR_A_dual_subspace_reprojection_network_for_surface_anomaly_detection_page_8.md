Page 8

The generated segmentation mask M is of the same resolution as the feature maps. A simple Unet-like upsampling module is thus used to resample the mask to full resolution. The input to the network is a depth-wise concatenation of the input image I and bilinearly upsampled mask M . The output is the final full-resolution mask M r (Figure 2).

## 3.6 Feature-space surface anomaly generation

The purpose of anomaly generator is to simulate near-in-distribution anomalies of various shapes and sizes with diverse visual appearances to (i) learn normal appearance subspace restriction in the object-specific appearance decoder (Section 3.3) and (ii) to specialize the anomaly detection module (Section 3.4) for detection of potentially gentle appearance deviations of anomalies from a diverse within-class normal appearance.

We propose a method that leverages the learned quantized subspace in DSR to generate such training anomalies as follows. An anomaly-free input image I is encoded into a VQ subspace representation Q and an anomaly mask M gt is generated by sampling a Perlin noise [14], with values 1 indicating anomalous pixels. The features in Q corresponding to the anomaly indicators in M gt are replaced by sampling from the set of codebook features K .

Sampling without constraints will likely lead to significant appearance changes on anomalous pixels, resulting in trivial out-of-distribution reconstructed images. On the other hand, if the closest vectors are sampled that are too similar to the normal appearance, they will likely lead to false-positive detections.

We thus first define a similarity bound on all features for a given image n ∼ U [ λ s N K , N K ], where N K is the number of codebook vectors and λ s is the similarity bound parameter. Then we replace each feature in Q , indicated by M gt , with one of its near neighbors from the codebook feature vectors, sampled uniformly, i.e., k ∼ U [ λ s N K , n ]. In all experiments λ s is 0 . 05, therefore, excluding the 5% of most similar vectors to prevent false-positive generation, while prioritizing the selection of the features close to the vector to be replaced to encourage the generation of near-in-distribution anomalies.

## 3.7 DSR training procedure