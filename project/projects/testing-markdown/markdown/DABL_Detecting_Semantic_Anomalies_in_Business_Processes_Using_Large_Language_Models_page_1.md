Page 1

## DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models

## Wei Guan 1 , Jian Cao 1 * , Jianqi Gao 1 , Haiyan Zhao 2 , Shiyou Qian 1

1 Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China 2 Department of Computer Science and Engineering, University of Shanghai for Science and Technology, Shanghai, China { guan-wei, cao-jian, 193139, qshiyou } @sjtu.edu.cn, zhaohaiyan1992@foxmail.com

## Abstract

Detecting anomalies in business processes is crucial for ensuring operational success. While many existing methods rely on statistical frequency to detect anomalies, it's important to note that infrequent behavior doesn't necessarily imply undesirability. To address this challenge, detecting anomalies from a semantic viewpoint proves to be a more effective approach. However, current semantic anomaly detection methods treat a trace (i.e., process instance) as multiple event pairs, disrupting long-distance dependencies. In this paper, we introduce DABL, a novel approach for detecting semantic anomalies in business processes using large language models (LLMs). We collect 143,137 real-world process models from various domains. By generating normal traces through the playout of these process models and simulating both ordering and exclusion anomalies, we fine-tune Llama 2 using the resulting log. Through extensive experiments, we demonstrate that DABL surpasses existing state-of-the-art semantic anomaly detection methods in terms of both generalization ability and learning of given processes. Users can directly apply DABL to detect semantic anomalies in their own datasets without the need for additional training. Furthermore, DABL offers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies.

## Introduction

Business process anomaly detection is geared towards identifying undesired behavior occurring during process execution, serving as a crucial component in guaranteeing the efficient and dependable operation of businesses. By pinpointing anomalies within business processes, these detection techniques facilitate timely intervention, maintenance, and optimization, consequently bolstering overall well-being.

Over the past few decades, notable advancements have been achieved in business process anomaly detection. Fig. 1 illustrates a comparison of various applicable methods for accomplishing this task. Traditional statistical-based approaches (Lu, Fang, and Fang 2022; Ko and Comuzzi 2022; Nolle et al. 2022; Guan et al. 2024) rely on analyzing statistical frequencies to identify anomalies. However, infrequent behavior is not necessarily anomalous; it may represent rare but acceptable behavior. Conversely, frequent behavior may

Figure 1: Comparison between our DABL with existing methods.

<!-- image -->

not always be normal. Furthermore, these methods focus on providing anomaly scores and require manual specification of thresholds to distinguish between normal and anomalous instances, which is not suitable for real-world applications. Alternatively, methods based on conformance checking (Ebrahim and Golpayegani 2022; Sarno, Sinaga, and Sungkono 2020; Sinaga and Sarno 2016) detect anomalies by assessing the alignment between traces and their corresponding process models. Yet, accurately capturing complex processes within a process model remains a challenge, thereby restricting the utility of such approaches. The concept of semantic anomaly detection , recently introduced, addresses these challenges by identifying anomalies from a semantic viewpoint. For example, it can detect irregularities such as a claim being paid after having been rejected. Its grounding in natural language analysis allows for the consideration of typical behavior in standard processes, eliminating the necessity of having a specific process model at hand. However, existing semantic-based anomaly detection methods (van der Aa, Rebmann, and Leopold 2021; Caspary, Rebmann, and van der Aa 2023) treat a trace as multiple event pairs, disrupting long-distance dependencies and thus limiting their accuracy. Additionally, these methods interpret the cause of anomalies by providing anomalous event pairs, which can be confusing.

Recently, there have been significant advancements in large language models (LLMs). Due to their remarkable language comprehension abilities, LLMs such as GPT-3.5

(Ouyang et al. 2022), GPT-4 (Achiam et al. 2023), Llama 2 (Touvron et al. 2023), and GLM-3 (Zeng et al. 2022) have shown proficiency in tasks like summarization, paraphrasing, and instruction following in zero-shot scenarios. However, in the context of semantic anomaly detection in business processes, their performance is limited by a lack of prior domain knowledge. As illustrated in Fig. 1, they often struggle to provide specific answers.

To address the aforementioned issues, we propose DABL, a fine-tuned LLM designed to detect semantic anomalies in business processes. Due to the lack of event logs comprising traces from various domains with rich semantic information, we generated our training dataset by playing out 143,137 real-world process models from three different process model datasets. This resulted in 1,574,381 normal traces. The collected process models cover a broad range of domains, including common processes related to order and request handling, as well as specialized processes in fields such as software engineering and healthcare. Utilizing the generated normal traces, we then created synthetic anomalous traces. We introduced ordering anomalies, where activities should be executed in a different sequence (e.g., 'accept request' followed by 'check request'), and exclusion anomalies, where certain activities should not occur together within the same trace without an intermediate activity (e.g., 'refusing the application' followed by 'accepting the application' without 'reapplying' in between). These generated normal and anomalous traces collectively form the training dataset. Finally, by incorporating traces into question and answer content, we fine-tune the Llama 2-Chat 13B model (Touvron et al. 2023), an open-source LLM, using QLoRA (Dettmers et al. 2024), to create a generic model capable of detecting semantic anomalies in business processes. Compared to existing anomaly detection methods, DABLoffers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies. Extensive experiments show that DABL surpasses state-of-the-art methods in both generalization ability and learning of given processes. Thanks to its strong generalization ability, users can apply our opensource, fine-tuned model directly to their datasets without the need for additional training.

Our contributions are summarized as follows:

- · We introduce DABL, an innovative method for finetuning large language models (LLMs) to detect semantic anomalies in business processes.
- · We introduce novel techniques for simulating business process anomalies, encompassing ordering anomalies and exclusion anomalies, thereby enabling precise finetuning of LLMs.
- · Extensive experiments demonstrate that DABL outperforms state-of-the-art methods in both generalization ability and the learning of given processes. Tests on real-world datasets confirm the practical effectiveness of DABL.

## Related Work

## Business Process Anomaly Detection

Existing business process anomaly detection methods can be divided into three categories: statistical-based, conformance checking-based, and semantic-based.

Statistical-based Methods Some of these methods construct probabilistic models to infer the probability values (i.e., anomaly score) of traces. For example, HPDTMC (Yang et al. 2020) constructs discrete-time Markov chains (DTMC) and introduces hitting probabilities (HP). EDBN (Pauwels and Calders 2019a,b) extends dynamic Bayesian networks by adding functional dependencies. PN-BBN (Lu, Fang, and Fang 2022) extends Petri nets by incorporating Bayesian networks. Other methods convert traces into vector representations and then detect anomalies using data mining techniques such as local outlier factor (LOF) and isolation forest (IF). For example, activities are considered as words and encoded into vectors using the word2vec (Mikolov et al. 2013) technique in (Junior et al. 2020; Vertuam Neto et al. 2021). Additionally, Trace2vec (De Koninck, vanden Broucke, and De Weerdt 2018), extended from doc2vec and n-gram, is used to encode traces in (Rullo et al. 2020). Furthermore, the authors in (Ko and Comuzzi 2022, 2021) employ one-hot encoding to convert traces into vector representations and detect anomalies using statistical leverage (Hoaglin and Welsch 1978). Recently, deep learning has been adopted to detect anomalies based on the reconstruction error. Given that traces exhibit sequential data characteristics, the authors in (Guan et al. 2023; Nolle et al. 2022; Krajsic and Franczyk 2021) embed LSTM or GRU within the autoencoder to enhance the model's reconstruction capabilities. The authors in (Huo et al. 2021; Guan et al. 2024; Niro and Werner 2024) transform traces into graphs and utilize graph neural networks (GNNs) to generate graph encodings, identifying anomalies by evaluating the reconstruction error of the graphs or traces.

Statistical-based methods detect anomalies by analyzing statistical frequencies. However, infrequent behavior is not necessarily anomalous, as it may represent rare but acceptable behavior. Conversely, frequent behavior may not always be normal.