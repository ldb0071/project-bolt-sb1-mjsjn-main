Page 8

[P and Abraham, 2020] Deepak P and Savitha Sam Abraham. Fair Outlier Detection. In arXiv:2005.09900 , 2020.

[Pang et al. , 2020] Guansong Pang, Chunhua Shen, Longbing Cao, and Anton van den Hengel. Deep Learning for Anomaly Detection: A Review. arXiv:2007.02500 [cs, stat] , July 2020.

[Pang et al. , 2021] Guansong Pang, Choubo Ding, Chunhua Shen, and Anton van den Hengel. Explainable Deep Few-shot Anomaly Detection with Deviation Networks. arXiv:2108.00462 [cs] , August 2021.

[Panjei et al. , 2022] Egawati Panjei, Le Gruenwald, Eleazar Leal, Christopher Nguyen, and Shejuti Silvia. A survey on outlier explanations. The VLDB Journal , 2022.

[Preece et al. , 2018] Alun Preece, Dan Harborne, Dave Braines, Richard Tomsett, and Supriyo Chakraborty. Stakeholders in Explainable AI. arXiv:1810.00184 [cs] , September 2018.

[Ruff et al. , 2020] Lukas Ruff, Robert A. Vandermeulen, Nico Gornitz, Alexander Binder, Emmanuel Muller, Klaus-Robert Muller, and Marius Kloft. Deep SemiSupervised Anomaly Detection. In ICLR , February 2020.

[Ruff et al. , 2021] Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, Gr'egoire Montavon, Wojciech Samek, Marius Kloft, Thomas G. Dietterich, and

Klaus-Robert Muller. A Unifying Review of Deep and Shallow Anomaly Detection. Proceedings of the IEEE , 109(5):756-795, May 2021.

[Shekhar et al. , 2021] Shubhranshu Shekhar, Neil Shah, and Leman Akoglu. FairOD: Fairness-aware Outlier Detection. In AIES , 2021.

[Shuhan et al. , 2020] Yuan Shuhan, Zheng Panpan, Wu Xintao, and Tong Hanghang. Few-shot Insider Threat Detection. In CIKM , 2020.

[Sipple, 2020] John Sipple. Interpretable, Multidimensional, Multimodal Anomaly Detection with Negative Sampling for Detection of Device Failure. In ICML , 2020.

[Song et al. , 2021] Hanyu Song, Peizhao Li, and Hongfu Liu. Deep Clustering based Fair Outlier Detection. In KDD , June 2021.

[Su et al. , 2019] Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network. In KDD , 2019.

[Takeishi and Kawahara, 2020] Naoya Takeishi and Yoshinobu Kawahara. On Anomaly Interpretation via Shapley Values. arXiv:2004.04464 [cs, stat] , April 2020.

[Venkataramanan et al. , 2020] Shashanka Venkataramanan, Kuan-Chuan Peng, Rajat Vikram Singh, and Abhijit Mahalanobis. Attention Guided Anomaly Localization in Images. In ECCV , July 2020.

[Xu et al. , 2019] Depeng Xu, Shuhan Yuan, and Xintao Wu. Achieving differential privacy and fairness in logistic regression. In Companion of WWW , 2019.

[Xu et al. , 2020] Jinghui Xu, Yu Wen, Chun Yang, and Dan Meng. An Approach for Poisoning Attacks Against RNNBased Cyber Anomaly Detection. In TrustCom , 2020.

[Xu et al. , 2021a] Depeng Xu, Wei Du, and Xintao Wu. Removing disparate impact on model accuracy in differentially private stochastic gradient descent. In KDD , 2021.

[Xu et al. , 2021b] Han Xu, Xiaorui Liu, Yaxin Li, Anil Jain, and Jiliang Tang. To be Robust or to be Fair: Towards Fairness in Adversarial Training. In ICML , 2021.

[Xu et al. , 2021c] Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: Methods, challenges and directions. arXiv preprint arXiv:2108.04417 , 2021.

[Zhang and Davidson, 2021] Hongjing Zhang and Ian Davidson. Towards Fair Deep Anomaly Detection. In ACM FAccT , 2021.

[Zhang and Wu, 2017] Lu Zhang and Xintao Wu. Antidiscrimination learning: A causal modeling-based framework. IJDSA , 4(1):1-16, 2017.

[Zhang et al. , 2020] Wei Emma Zhang, Quan Z. Sheng, Ahoud Alhazmi, and Chenliang Li. Adversarial Attacks on Deep-learning Models in Natural Language Processing: A Survey. TIST , 11(3):24:1-24:41, April 2020.