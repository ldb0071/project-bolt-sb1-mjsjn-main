Page 28

The basic operations of Stage 2/3/4 are similar. At the beginning of Stage 2 - Stage 4, a patch merging operation is performed to reduce the number of tokens, and the adjacent 2 Ã— 2 tokens are merged. Each stage changes the dimensionality of the tensor, forming a hierarchical representation that can be conveniently replaced by a backbone network for various visual tasks.

Swin-Transformer also further improves the Position Encoding method by superimposing the Position Encoding on the attention matrix instead of the sin and cos Position Encoding function of the Vanilla Transformer.

Due to the excellent performance of Swin-Transformer in CV tasks, it has been applied to anomaly detection tasks in CV domains such as image and video. Han et al. [4] used the Swin-Transformer architecture with GP to extract image features. They further modified the loss function based on Swin-Transformer by replacing it with a loss function combining Negative Log Likelihood (NLL) and GP. Their work has strongly demonstrated the excellent performance of Transformer architecture for Autonomous Driving Systems (ADS) scene-aware anomaly detection. Swin-Transformer outperforms traditional single-class classifiers based on kernel SVM and machine learning

classifiers based on Decision Trees on several datasets with different subtasks in the autonomous driving fields (Baidu Apollo for GPS spoofing attacks, GTSRB for traffic sign attacks, Tusimple for detecting lane attacks). On this basis, Han et al. [89] added federated learning and life-long learning to Swin-Transformer and named the system ADS-Lead. ADS-Lead can continuously collect data and update models in real-time, to better perform online anomaly monitoring and anomaly detection tasks. Concretely, ADS-Lead's federated learning technology communicates from each vehicle's C-ITS system to the server cluster using V2C technology. The server receives multiple vehicle information and aggregates it into a gradient vector, then averages it for calculation, returning the new model to each vehicle in the C-ITS system. Each vehicle can use the latest system for anomaly detection, while the entire system is updated asynchronously, meaning that the system does not need to wait for all the information from each vehicle to be in place before calculation, but can receive information, for realtime calculation and real-time feedback. Jiang et al. [90] proposed the use of Masked Swin Transformer Unet for image anomaly detection tasks. They modified the method of determining anomalies from image reconstruction to image inpainting and utilized the powerful global learning ability of Swin Transformer to inpaint the masked area. By dividing the input image into nonoverlapping image patches, putting the image patches into a Swin Transformer-based encoder to extract global contextual features, dual upsampling them with the decoder, and fusing with multiscale features from the encoder via skip connections, they generated masked patches and achieved high detection accuracy.

## 4.6 Anomaly detection based on Informer