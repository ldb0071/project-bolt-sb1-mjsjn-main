Page 7

## 4. Experiments

## 4.1. Experimental Setup

Datasets. Following prior OSAD studies [15, 32], we conduct extensive experiments on nine real-world anomaly detection datasets, including five industrial defect inspection datasets (MVTec AD [5], AITEX [42], SDD [44], ELPV [13] and Optical [50]), one planetary exploration dataset (Mastcam [20]), and three medical datasets (HeadCT [40], BrainMRI [40] and Hyper-Kvasir [7]). Depending on how we sample the seen anomaly examples, two protocols are used to evaluate the detection performance, the general and hard settings [15]. The general setting assumes the anomaly examples are randomly sampled from the anomaly classes, while the hard setting presents a more challenging case where the anomaly examples are sampled exclusively from only one class to evaluate the generalization ability to novel or unseen anomaly classes. Both protocols are used in our experiments. Following [15], we also evaluate the performance with the number of anomaly examples set to respectively M = 10 and M = 1 . Further details about these datasets are available in Appendix A .

Competing Methods and Evaluation Metrics. AHL is compared with five closely related state-of-the-art (SOTA) methods, including MLEP [24], SAOE [22, 30, 45], FLOS [23], DevNet [32], and DRA [15]. MLEP, DevNet and DRA are specifically designed for OSAD. SAOE is a supervised detector augmented with synthetic anomalies and outlier exposure, while FLOS is a focal-loss-based imbalanced classifier. For evaluation metrics, we adopt the widely used Area Under ROC Curve (AUC) to measure the performance of all methods and settings. All reported results are averaged results over three independent runs, and stated otherwise.

Implementation Details. To generate a diverse set of

Table 1. AUC results(mean±std) on nine real-world AD datasets under the general setting. Best results and the second-best results are respectively highlighted in red and bold .' ↑ ' (' ↑ ') indicates increased performance over DRA (DevNet).

| Dataset                       | SAOE                          | MLEP                          | FLOS                          | DevNet                        | DRA                           | AHL (DevNet)                  | AHL (DRA)                     |
|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|
| Ten Anomaly Examples (Random) | Ten Anomaly Examples (Random) | Ten Anomaly Examples (Random) | Ten Anomaly Examples (Random) | Ten Anomaly Examples (Random) | Ten Anomaly Examples (Random) | Ten Anomaly Examples (Random) | Ten Anomaly Examples (Random) |
| AITEX                         | 0.874±0.024                   | 0.867±0.037                   | 0.841±0.049                   | 0.889±0.007                   | 0.892±0.007                   | 0.903±0.011 ↑                 | 0.925±0.013 ↑                 |
| SDD                           | 0.955±0.020                   | 0.783±0.013                   | 0.967±0.018                   | 0.985±0.004                   | 0.990±0.000                   | 0.991±0.001 ↑                 | 0.991±0.000 ↑                 |
| ELPV                          | 0.793±0.047                   | 0.794±0.047                   | 0.818±0.032                   | 0.843±0.001                   | 0.843±0.002                   | 0.849±0.003 ↑                 | 0.850±0.004 ↑                 |
| Optical                       | 0.941±0.013                   | 0.740±0.039                   | 0.720±0.055                   | 0.785±0.012                   | 0.966±0.002                   | 0.841±0.010 ↑                 | 0.976±0.004 ↑                 |
| Mastcam                       | 0.810±0.029                   | 0.798±0.026                   | 0.703±0.029                   | 0.797±0.021                   | 0.849±0.003                   | 0.825±0.020 ↑                 | 0.855±0.005 ↑                 |
| BrainMRI                      | 0.900±0.041                   | 0.959±0.011                   | 0.955±0.011                   | 0.951±0.007                   | 0.971±0.001                   | 0.959±0.008 ↑                 | 0.977±0.001 ↑                 |
| HeadCT                        | 0.935±0.021                   | 0.972±0.014                   | 0.971±0.004                   | 0.997±0.002                   | 0.978±0.001                   | 0.999±0.003 ↑                 | 0.993±0.002 ↑                 |
| Hyper-Kvasir                  | 0.666±0.050                   | 0.600±0.069                   | 0.773±0.029                   | 0.822±0.031                   | 0.844±0.001                   | 0.873±0.009 ↑                 | 0.880±0.003 ↑                 |
| MVTec AD (mean)               | 0.926±0.010                   | 0.907±0.005                   | 0.939±0.007                   | 0.948±0.005                   | 0.966±0.002                   | 0.954±0.003 ↑                 | 0.970±0.002 ↑                 |
| One Anomaly Example (Random)  | One Anomaly Example (Random)  | One Anomaly Example (Random)  | One Anomaly Example (Random)  | One Anomaly Example (Random)  | One Anomaly Example (Random)  | One Anomaly Example (Random)  | One Anomaly Example (Random)  |
| AITEX                         | 0.675±0.094                   | 0.564±0.055                   | 0.538±0.073                   | 0.609±0.054                   | 0.693±0.031                   | 0.704±0.004 ↑                 | 0.734±0.008 ↑                 |
| SDD                           | 0.781±0.009                   | 0.811±0.045                   | 0.840±0.043                   | 0.851±0.003                   | 0.907±0.002                   | 0.864±0.001 ↑                 | 0.909±0.001 ↑                 |
| ELPV                          | 0.635±0.092                   | 0.578±0.062                   | 0.457±0.056                   | 0.810±0.024                   | 0.676±0.003                   | 0.828±0.005 ↑                 | 0.723±0.008 ↑                 |
| Optical                       | 0.815±0.014                   | 0.516±0.009                   | 0.518±0.003                   | 0.513±0.001                   | 0.880±0.002                   | 0.547±0.009 ↑                 | 0.888±0.007 ↑                 |
| Mastcam                       | 0.662±0.018                   | 0.625±0.045                   | 0.542±0.017                   | 0.627±0.049                   | 0.709±0.011                   | 0.644±0.013 ↑                 | 0.743±0.003 ↑                 |
| BrainMRI                      | 0.531±0.060                   | 0.632±0.017                   | 0.693±0.036                   | 0.853±0.045                   | 0.747±0.001                   | 0.866±0.004 ↑                 | 0.760±0.013 ↑                 |
| HeadCT                        | 0.597±0.022                   | 0.758±0.038                   | 0.698±0.092                   | 0.755±0.029                   | 0.804±0.010                   | 0.781±0.007 ↑                 | 0.825±0.014 ↑                 |
| Hyper-Kvasir                  | 0.498±0.100                   | 0.445±0.040                   | 0.668±0.004                   | 0.734±0.020                   | 0.712±0.010                   | 0.768±0.015 ↑                 | 0.742±0.015 ↑                 |
| MVTec AD (mean)               | 0.834±0.007                   | 0.744±0.019                   | 0.792±0.014                   | 0.832±0.016                   | 0.889±0.013                   | 0.843±0.021 ↑                 | 0.901±0.003 ↑                 |

anomaly distributions, our proposed approach uses a mixture of randomly selected normal clusters and labeled anomaly examples to create each individual anomaly distribution data D i . Specifically, k -means clustering is first used to partition normal samples into three normal clusters ( i.e ., k = 3 is used). Then two randomly selected clusters are chosen, combining with the seen anomalies, to construct D i , having one normal clusters and 50% of the seen anomaly set as the support set D s i while the rest of samples are used as the query set D q i (Under the protocol of having only one seen anomaly example, the example is included in both sets). This helps effectively simulate open-set environments with partially observed anomaly distributions. To further increase the heterogeneity in within and between the anomaly distribution datasets, we randomly pick one of the three popular anomaly generation techniques, including CutMix [60], CutPaste [22], and DRAEM Mask [63], to generate and inject pseudo anomalies into the support and query sets of D i . To guarantee the openness w.r.t. the pseudo anomaly detection, the pseudo anomalies in D s i and D q i are generated from two different anomaly generation approaches. For each dataset, T = 7 is used in generating the individual anomaly distribution data. c j is set to 1.0 when x j represents unseen anomaly samples, and 0.5 when x j represents seen anomaly or unseen normal samples.

AHL is a generic framework, under which features and loss functions from existing OSAD models can be easily plugged in as the base features and the base loss. Particularly, the image features are extracted from one of the OSAD model ( e.g ., DRA), and then AHL is trained using our proposed loss function built on the base loss (see Eq.

4). DRA [15], DevNet [32] and BGAD [58] are the current SOTA models for OSAD, but BGAD uses quite different benchmark datasets from the other two. Our experiments strictly follow the seminal OSAD evaluation protocol and benchmarks used in DRA [15] and DevNet [32], and choose DRA [15] and DevNet [32] to respectively plug in AHL , denoting as AHL (DRA) and AHL (DevNet) . Adam is used as the optimizer. The initial learning rate for learning heterogeneous T base models is set to 0.0002, while that for the unified AD model g is set to 0.005. In the selfsupervised importance score estimator, a two-layer Bidirectional LSTM [67] is used as the backbone, with the hidden dimension set to 7. It is followed by a fully-connected layer with 14 hidden nodes, before the prediction layer. The initial learning rate is set to 0.02 for this component.