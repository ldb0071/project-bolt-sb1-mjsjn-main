Page 3

Figure 1 shows an example of anomalous and non-anomalous instances, and inexact anomaly sets in a two-dimensional instance space. For unsupervised methods, it is difficult to detect test anomalous instance 'A' since some instances are located around it. Unsupervised methods consider that an instance is anomalous when there are few instances around it. Since supervised methods can use label information, they can correctly detect test anomalous instance 'A'. However, they might not detect test anomalous instance 'B' since there are no labeled instances near it. In addition, with supervised methods that consider all the instances in inexact anomaly sets are anomaly, non-anomalous instances around training instances in the inexact anomaly sets (colored triangles in Figure 1) would be misclassified as anomaly. On the other hand, the proposed method detects 'A' using label information and 'B' by incorporating an unsupervised anomaly detection mechanism. Also, it would not detect non-anomalous instances as anomaly since it can handle inexact information.

The remainder of the paper is organized as follows. In Section 2, we briefly review related work. In Section 3, we introduce AUC, which is the basis of the inexact AUC. In Section 4, we present the inexact AUC, define our task, and propose our method for supervised anomaly detection using inexact labels. In Section 5, we experimentally demonstrate the effectiveness of our proposed method using various datasets by comparing with existing anomaly detection and multiple instance learning methods. Finally, we present concluding remarks and discuss future work in Section 6.

## 2 Related work

Inexact labels in classification tasks have been considered in multiple instance learning methods (Dietterich et al., 1997; Maron and Lozano-P'erez, 1998; Babenko et al., 2009; Wu et al., 2015; Cinbis et al., 2017), where labeled sets are given for training. For a binary classification task, a set is labeled negative if all the instances in it are negative, and it is labeled positive if it contains at least one positive instance. An advantage of the proposed method over existing multiple instance learning methods is that the proposed method works well with a small number of inexact anomaly labels using inexact AUC

maximization and incorporating an unsupervised anomaly detection mechanism, where we exploit the characteristics of anomaly detection tasks. Existing multiple instance learning methods are not robust to class imbalance (Herrera et al., 2016; Carbonneau et al., 2018).

Anomaly detection is also called outlier detection (Hodge and Austin, 2004) or novelty detection (Markou and Singh, 2003). Many unsupervised methods have been proposed, such as the local outlier factor (Breunig et al., 2000), one-class support vector machines (Scholkopf et al., 2001), isolation forests (Liu et al., 2008), and density estimation based methods (Shewhart, 1931; Eskin, 2000; Laxhammar et al., 2009). However, these methods cannot use label information. Although supervised anomaly detection methods have been proposed to exploit label information (Nadeem et al., 2016; Gao et al., 2006; Das et al., 2016, 2017; Munawar et al., 2017; Pimentel et al., 2018; Akcay et al., 2018; Iwata and Yamanaka, 2019), they cannot handle inexact anomaly labels. A number of AUC maximization methods have been proposed (Cortes and Mohri, 2004; Brefeld and Scheffer, 2005; Ying et al., 2016; Fujino and Ueda, 2016; Narasimhan and Agarwal, 2017; Sakai et al., 2018) for training on class imbalanced data. However, these methods do not consider inexact labels.

## 3 Preliminaries: AUC

Let X be an instance space, and let p A and p N be probability distributions over anomalous and nonanomalous instances in X . Suppose that a : X â†’ R is an anomaly score function, and anomaly detection is carried out based on its sign: