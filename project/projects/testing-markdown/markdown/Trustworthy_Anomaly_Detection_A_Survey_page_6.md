Page 6

[Breunig et al. , 2000] Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng, and Jorg Sander. LOF: Identifying density-based local outliers. ACM SIGMOD Record , 29(2):93-104, May 2000.

[Brown et al. , 2018] Andy Brown, Aaron Tuor, Brian Hutchinson, and Nicole Nichols. Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection. In MLCS , 2018.

[Bulusu et al. , 2021] Saikiran Bulusu, Bhavya Kailkhura, Bo Li, Pramod K. Varshney, and Dawn Song. Anomalous Example Detection in Deep Learning: A Survey. arXiv:2003.06979 , 2021.

[Chakraborty et al. , 2018] Anirban Chakraborty, Manaar Alam, Vishal Dey, Anupam Chattopadhyay, and Debdeep Mukhopadhyay. Adversarial Attacks and Defences: A Survey. arXiv:1810.00069 [cs, stat] , September 2018.

[Chen et al. , 2017] Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning. arXiv:1712.05526 [cs] , December 2017.

[Cheng et al. , 2021] Lu Cheng, Kush R. Varshney, and Huan Liu. Socially Responsible AI Algorithms: Issues, Purposes, and Challenges. arXiv:2101.02032 , 2021.

[Davidson and Ravi, 2020] Ian Davidson and S. S. Ravi. A Framework for Determining the Fairness of Outlier Detection. ECAI 2020 , pages 2465-2472, 2020.

[Dressel and Farid, 2018] Julia Dressel and Hany Farid. The accuracy, fairness, and limits of predicting recidivism. Science advances , 4(1), 2018.

[Du et al. , 2018] Mengnan Du, Ninghao Liu, and Xia Hu. Techniques for Interpretable Machine Learning. arXiv:1808.00033 [cs, stat] , July 2018.

[Du et al. , 2020] Min Du, Ruoxi Jia, and Dawn Song. Robust anomaly detection and backdoor attack detection via differential privacy. In ICLR , April 2020.

[Dwork and Roth, 2014] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical Computer Science , 9(34):211-407, 2014.

[Fan and Xiong, 2013] Liyue Fan and Li Xiong. Differentially Private Anomaly Detection with a Case Study on Epidemic Outbreak Detection. In ICDMW , 2013.

[Goodfellow et al. , 2015] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and Harnessing Adversarial Examples. arXiv:1412.6572 , 2015.

[Goodge et al. , 2020] Adam Goodge, Bryan Hooi, See Kiong Ng, and Wee Siong Ng. Robustness of Autoencoders for Anomaly Detection Under Adversarial Impact. In IJCAI , 2020.

[Han et al. , 2021] Xiao Han, He Cheng, Depeng Xu, and Shuhan Yuan. InterpretableSAD: Interpretable anomaly detection in sequential log data. In IEEE Big Data , 2021.

[Hendrycks et al. , 2019] Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song. Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty. In NeurIPS , October 2019.

[Jacob et al. , 2021] Vincent Jacob, Fei Song, Arnaud Stiegler, Bijan Rad, Yanlei Diao, and Nesime Tatbul. Exathlon: A Benchmark for Explainable Anomaly Detection over Time Series. arXiv:2010.05073 [cs] , 2021.