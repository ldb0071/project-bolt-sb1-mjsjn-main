Page 43

You et al. [110] used BERT to extract corresponding features from unstructured text data and adopted MLP for anomaly detection. They used a projected gradient descent method to enhance recognition by jointly minimizing the amount of normal class data and updating centers of the closed hypersphere, and further employing a smaller proportion of anomaly-labeled data. They considered the model's anomaly detection capability by two application scenarios: detecting irrelevant sentences in the

topic and detecting mislabeled text data that do not belong to any known class type. LAnoBERT [52] focuses on the MLM mechanism. If the log sequence is normal, the prediction probability of the masked words is high, because it conforms to the log format learned by the model during the training phase. If the model has a lower prediction probability and a higher error (a larger distance metric between the predicted word and the originally masked word), the log is considered an anomaly log. However, LAnoBERT also reveals the shortcomings of the BERT model. Original BERT requires a lot of time to learn large-scale log data, and the training time should be shortened by effectively selecting the log data required for training and constructing a more lightweight BERT model to cope with the real-time anomaly detection task. In addition, it would cost too much performance to construct a BERT model for each dataset for anomaly detection. Therefore, a model that can accurately understand the nature of log data during the pre-training stage should be used, and fine-tuning operations should be carried out according to different log datasets, to improve the anomaly detection performance significantly. Le et al. [35], on the other hand, applied BERT to extract the raw log message semantics and converted them into semantic vectors. They argued that existing log parsing algorithms, such as Drain [111], can invalidate the entire anomaly detection approach due to an initial parsing error. Existing log parsing algorithms can not handle OOV words in new logs well, thus losing semantic information when detecting anomalies. In addition, current log parsing methods may generate errors due to semantic misinterpretation. However, some researchers also put forward a different viewpoint. This article will further discuss whether to use log parsing in Section 7.1.

Ott et al. [112] evaluated the performance of several different language models, including BERT, GPT-2, and XL, on anomaly detection tasks for log data. They first preserved the semantics of log messages by pre-training these language models, mapped them to the embedding of log vectors, used Bi-LSTM neural networks to connect the embedding vectors through time, and applied the deviation between the detection system and the expected behavior to anomaly detection. To further improve the performance of anomaly detection, Hirakawa et al. [113] used Optuna [114], a hyperparameter automatic optimization framework, and converted log messages into features (distributed expressions) rather than log keys. However, they concluded through experimental analysis that the current BERT model is still not very stable, and the performance is very sensitive to hyperparameters and learning rates. The size change of the dataset will further affect the performance of the model. Therefore, the BERT stable learning strategy should be further investigated in the future. TS-BERT [115] uses MLM task to learn behavioral features of time series from a large amount of unlabeled data in the pre-training phase and uses the SR method to generate labels, which in turn eliminates the dependence of BERT on labels. However, the author still found that the model performed better when partially labeled data was provided.

Anomaly Adapter [116] uses RoBERTa to encode logs in byte form, uses Adapters to learn log structures and anomaly types, and additionally introduces transfer learning methods. The purpose of the Adapter is to fine-tune the structure of RoBERTa, so that the model does not have to be retrained for each data source, allowing the model to adapt to different anomaly datasets, similar to the fine-tune mechanism in BERT. Zhou

et al. [117] used the contrastive loss to fine-tune RoBERTa and improved the compactness of the representation. They also applied the method of Mahalanobis distance and contrastive learning to the RoBERTa model. Henrycks et al. [118] comprehensively considered the performance of many BERT variants for the OOD detection task on NLP datasets. They measured the performance of BERT, BERT Large, RoBERTa, ALBERT [119] and DistilBERT [120] on various NLP tasks, including but not limited to emotion analysis, reading comprehension, etc. Both ALBERT and DistilBERT reduce memory consumption and improve the training speed of BERT.