Page 34

x ' i = ˜ x i + MHSA (˜ x i ) (20)

x '' i = x ' i + Conv ( x ' i ) (21)

y i = Layernorm ( x '' i + 1 2 FFN ( x '' i )) (22)

Conformer has the advantage of both local and global feature extraction capabilities. Stowell et al. [93] used Conformer to extract sequence information from the entire audio input for DCASE2020 unsupervised anomaly sound detection. They also applied the anomaly score mechanism of the GMM method to improve anomaly detection accuracy and achieved excellent performance in this challenging task. Yella et al. [94] adopted the Soft-Sensing Conformer for the wafer fault diagnosis classification tasks. They similarly concluded that Vanilla Transformer can effectively learn global location information for alleviating long-term dependency problems, but requires a large amount of data and suffers from quadratic complexity, while CNN can effectively learn local information. The process of their method is as follows: first, embedding the input, feeding the embedded data in the low dimensional space to the Conformer block. After receiving the output of multiple Conformer blocks, concatenating them and performing Global Averaging Pooling (GAP) operations. Finally, classifying the output through Y = ActivationFunc ( FFN ( Dropout ( z )), and converting to the probability output through the sigmoid function. The author additionally used the loss function SuperLoss of the curriculum learning method to address the problems of noise and high data imbalance in traditional learning models. Their extensive experiments on various datasets from Seagate Technology's wafer manufacturing process demonstrated the superior performance of Conformer.

Some researchers did not directly use the Conformer model but combined Transformer with CNN. In this paper, these methods are collectively referred to as convolutional Transformers. Although different from Conformer in terms of model structure, both essentially use the ability of convolution to extract local features to compensate for the deficiency of Transformer. Li et al. [65] used a convolution-based Transformer model for the main purpose of addressing the weakness of the Transformer's local perception. Their approach was to replace the linear projection unit in the Vanilla Transformer with depth-separable 1D convolution (DWConv1D), as shown in Figure 8: