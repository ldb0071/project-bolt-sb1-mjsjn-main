Page 2

Nevertheless, the task of distinguishing the ordinary from the extraordinary in videos is exceptionally challenging. Video anomaly detection typically lives within the domain of unsupervised learning due to the inherent scarcity of labeled anomalies and the impracticality of cataloging

the large array of possible anomalous events. The unpredictable nature of anomalies further adds to the complexity, making it difficult for models trained on 'normal' behavior to generalize and identify outliers effectively. This difficulty is magnified by the context-sensitive definition of what constitutes an anomaly within video data, as it can vary significantly from one setting to another. In the absence of sufficient examples of anomalous behavior during training, systems often struggle to accurately discern anomalies when they do occur, resulting in a high number of false positives or missed detections.

Traditional approaches to this challenge have relied on neural network architectures like AutoEncoders and UNets [7-10, 12, 16, 17, 23, 28, 30, 31, 33, 35, 37, 38, 40]. These models are trained to recreate 'normality' by learning to compress and then reconstruct input data with minimal loss. The underlying premise is that, by becoming adept at reconstructing normality, these networks would inherently struggle when faced with anomalies, thus allowing for their detection. However, there lies a catch-these systems do not necessarily learn an explicit distinction between normal and anomalous samples, it is only hoped that anomalies will pose a greater challenge for the reconstruction process.

To address this predicament, various methodologies have introduced pseudo-anomalies during the training phase, offering models a taste of the 'abnormal' to foster learning [1-4, 24, 41]. These strategies, however, often overlook a critical aspect: the quantification of the 'right level' of pseudo-anomaly. That is, how anomalous should pseudoanomalies be to represent real anomalies? Too small, and the pseudo-anomalies bare too close a resemblance to normal data; too high, and the model may fail to recognize genuine, more subtle, anomalies.

In our work, the innovation lies not just in the incorporation of pseudo-anomalies, but in the strategic introduction of a dynamic anomaly weight σ ( ℓ ) . This adapt-

lity is crucial, allowing our model the flexibility to discover the optimal threshold of anomaly intensity for effective learning. Rather than being constrained to a predetermined, static level of pseudo-anomaly - which might risk the model's overfitting to artificial quirks - the dynamic nature of σ ( ℓ ) entrusts the model with the autonomy to finetune this threshold. By doing so, the model is trained to differentiate between normal and anomalous patterns without being anchored to any specific level of anomaly defined by the user.

Our work also introduces the Distinction Loss, which works in tandem with σ ( ℓ ) , and is crafted to refine the model's discrimination capabilities. The Distinction Loss encourages the model to rebuild pseudo-anomalous frames to more closely resemble the normal state rather than the inputted anomalous one.

In the forthcoming chapters, we delve into the core of our research on Dynamic Distinction Learning (DDL) for video anomaly detection. We first begin by providing a brief overview of related work in Chapter 2. Chapter 3 outlines the methodology, detailing the DDL framework and its components. Chapter 4 describes the datasets considered for evaluation, leading to Chapter 5, which presents our findings through quantitative results. In our final chapter, Chapter 6, we provide ablation studies, highlighting the improvements offered by our work.

## 2. Related Work

The challenge of anomaly detection in video data is exacerbated by the predominance of normal behavior within datasets, leading to an inherent bias towards non-anomalous examples. Unsupervised learning, particularly through the use of AutoEncoders (AEs), has emerged as a preferred solution. AEs leverage the discrepancy between input and reconstructed output to identify anomalies, operating under the principle that unfamiliar anomalous inputs will result in significant reconstruction errors [7-10, 12, 28, 30, 33]. However, the challenge of accurately reconstructing normal samples to distinguish them from anomalies remains, with UNets and their skip connections offering a partial solution by improving reconstruction fidelity, albeit complicating the reliance on the latent space for anomaly detection [16, 17, 23, 31, 35, 37, 38, 40].

Recent advancements have explored the temporal dimension of video anomaly detection, employing AEs and UNets to reconstruct sequences or predict subsequent frames, under the hypothesis that anomalies will disrupt the model's ability to accurately predict future frames based on a sequence of normal frames [8, 12, 16, 17, 22, 23, 31, 33, 35, 37, 38, 40]. The integration of Transformers and attention mechanisms aims to capture the temporal characteristics of video data more effectively, enabling AutoEncoders and UNets to identify anomalies by focusing on the rela-

tionships between frames [12, 18, 36, 40]. Optical Flow has been utilized to enhance motion-related anomaly detection, providing a compact yet informative representation of temporal changes by capturing pixel motion between consecutive frames [5, 8, 33, 37, 39].