Page 71

At present, an important challenge for anomaly detection models is the problem of model interpretability. Since an important application of anomaly detection is to give the corresponding processing method based on the analysis of anomalies, it is not enough to give anomaly detection results for the corresponding model. The interpretability of a model affects its reliability and also facilitates more related tasks of anomaly detection, such as anomaly prediction, anomaly diagnosis, anomaly location, etc. Anomaly detection models should have a clear hierarchical, cascading structure to quantify and infer anomalies in an interpretable manner.

## Multi-class classification and overfitting problem.

Currently, most anomaly detection models are designed for binary classification problems. However, with the development of modern industrial systems and the increasing complexity of system architectures, there are higher requirements for anomaly detection tasks: a system should not only be able to detect anomalies in data sequence, but also give specific information about anomaly type. For a model, this entails the ability to effectively tackle multi-class classification tasks, learn distinctive features of various anomaly types from limited datasets, generalize this knowledge to accurately classify diverse anomalies, and offer appropriate indications during testing. This task is not as easy as adding the Softmax multi-classification layer in the model output part, because the model needs to learn different anomaly features and identify different types of anomalies in various datasets and application scenarios, which requires strong learning capability. Therefore, only a very few studies, such as GTF [31] and OODformer [37] have conducted experiments on multi-class classification tasks. Multi-class classification tasks require models that can accurately identify several different types of anomaly features and make correct decisions. Therefore, current multi-class classification anomaly detection models are all learned through supervised training. These models are trained under scenario-specific, data-limited datasets with multi-class classification labels, with weak generalization ability and unstable parameter selection. The data imbalance problem further limits the development of such models. Consequently, the multi-class classification problem is one of the severe challenges faced by Transformer models. In Section 7.3.4, we put forward further development directions for multi-class classification problems.

For Transformer, the goal is to produce a compact representation that can accurately represent normal samples while difficult to represent anomalous samples. However, if we restrict the latent space too much, it will lead to overfitting problems and is not conducive to the generalization of the model. Therefore, correct representation learning is crucial, especially in the context of data imbalance, where decision boundaries are difficult to determine. In this case, the choice of representation will affect the shape of normal distribution, and then affect the performance of anomaly diagnosis. Thus, selecting appropriate representation methods and solving the overfitting problem is one of the important challenges faced by Transformer.

## Decision boundary ambiguity problem.