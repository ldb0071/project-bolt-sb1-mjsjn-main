Page 2

a binary classification problem between normal and abnormal. The model is typically trained by using cross entropy on the time-series feature vectors of the logs. On the other hand, the unsupervised approach aims to learn a model describing normal system behavior through logs. This approach typically formulates the problem as a regression problem to predict the next log from a time series of past logs. The Recurrent Neural Networks (RNNs) and Transformers are used to learn the time series [12], [13].

Although these existing approaches have shown effectiveness in their respective experiments, they still have problems. First, the method using a log parser analyzes templates and parameters separately, so some important information is lost in the structuring process. In particular, it has been pointed out that the methods are unable to correctly detect log messages with unseen log templates that are not included in the training data [14]. Also, the performance of log anomaly detection is strongly dependent on the performance of the log parser, not on the detection algorithm itself [1]. Second, the methods based on supervised learning are not practical. Supervised learning has the potential to classify normal and abnormal data more accurately than unsupervised learning, but it requires a large number of labeled abnormal data in the training dataset for its training. However, in real-world software systems, most logs are normal and anomalous logs are rare. In addition, using anomaly logs for training requires manual labeling of log data by experts, which incurs a significant cost. Therefore, it is not realistic to train on labeled anomaly data in a real system, and supervised approaches are not suitable for realworld problems [15]. Finally, most unsupervised learningbased methods use time-series analysis of log messages. Recent studies have shown that almost all anomalous logs can be considered point anomalies that do not require time-series analysis [16]. Therefore, existing methods may examine an unnecessary number of log messages in an online detection setting before each model raises an anomaly alert [1]. Early detection of anomalies is important in real systems because it allows more time to consider more mitigating actions.

To solve the aforementioned problem, we propose LogELECTRA, a new log anomaly detection model that analyzes a single line of log messages more deeply on the basis of self-supervised anomaly detection. LogELECTRA specializes in detecting anomalous logs as point anomalies. To more accurately capture the characteristics of a single normal log message, LogELECTRA learns the context of the token sequence in a normal log message through an auxiliary task called Token Replacement Detection [17]. Then, in the evaluation phase, LogELECTRA judges whether the log message has a different context than the learned context and detects anomalies. Thus, LogELECTRA is robust to unseen log messages because it is parser-free, is practical because it is based on unsupervised approach, and has no detection time lag because it evaluates each line of the log. LogELECTRA was evaluated against the system log benchmark datasets Blue Gene/L, Spirit and Thunderbird. The results show that LogELECTRA improves the detection accuracy of anomalous logs compared with

## II. RELATEDWORK

In recent years, numerous methods have been proposed to analyze log data and detect anomalous logs using deep learning [5], [18]-[24]. These methods can achieve higher accuracy than conventional data mining based methods [25], [26]. In this section, we briefly introduce deep learning-based methods in the following.

Deeplog [20] is the first log anomaly detection method using deep learning. This method uses a log parser to split log messages into log templates and log parameters. It uses an unsupervised learning-based Long Short-Term Memory (LSTM) model to learn the pattern of normal log sequences in a system by predicting the next log event from a past sequence of log templates [27]. In the evaluation phase, the observed sequence of log messages is input into the model, and if the actual log event is included up to the top k -th of the predicted next log event, then the log message is considered normal.

LogAnomaly [19] utilizes an Attention-based Bi-LSTM model to perform unsupervised learning of both frequency and sequence patterns of log templates. It is a prediction-based anomaly detection model similar to DeepLog, which predicts the next log event and detects anomalies when observed log events differ from the predicted results. LogAnomaly is a log parser-dependent method, but utilizes the semantics of unseen logs by using a pre-trained word vector called Template2Vec.

LogRobust [24] performs supervised binary classification on time series of log messages using an Attention-based BiLSTM model. The method uses a pre-trained Word2Vec model called FastText and combining it with TF-IDF weights to obtain a representation vector of log templates [28], [29]. By utilizing pre-trained word vectors, LogRobust improves prediction performance for unseen logs.

CNN [23] is a classification-based log anomaly detection method proposed to detect anomalies in logs by performing time-series analysis with Convolutional Neural Networks [30]. By using time-series grouped log messages as features, CNN can automatically learn the relationship between log messages and detect anomalies with high accuracy.

Logsy [21] is a parser-free method using the Transformer. Logsy utilizes anomaly logs generated from another system as auxiliary data for training. Therefore, although it is a classification-based method, it does not require anomaly data from the monitored system during training.

PLELog [22] is a semi-supervised learning model that incorporates the Positive-Unlabeled (PU) Learning approach [31] to log anomaly detection. This method addresses the problem of insufficient labels using probabilistic label estimation from known normal logs. The detection model, which consists of an Attention-based Gated Recurrent Unit (GRU) neural network, is trained to classify log sequences into two classes: normal and abnormal.

All of these methods, with the exception of Logsy, analyze the time series of log messages, which causes unnecessary time loss between the actual occurrence of an abnormal log

message and its detection. Since these methods depend on a log parser, they also have limitations in terms of generalization to log messages that are not included in the training data. Logsy requires anomaly data for training, which comes with limitations for real-world use. Our proposed method, on the other hand, does not use time-series analysis, which allows for online detection without time lag. Furthermore, our method does not depend on a log parser or require labeled anomalies in the training data.