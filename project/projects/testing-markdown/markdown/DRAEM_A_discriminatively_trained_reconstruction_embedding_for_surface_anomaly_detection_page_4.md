Page 4

L rec ( I, I r ) = λL SSIM ( I, I r ) + l 2 ( I, I r ) , (2)

where λ is a loss balancing hyper-parameter.

Note that an additional training signal is acquired from the downstream discriminative network (Section 3.2), which performs anomaly localization by detecting the reconstruction difference.

## 3.2. Discriminative sub-network

The discriminative sub-network uses U-Net [21]-like architecture. The sub-network input I c is defined as the channel-wise concatenation of the reconstructive subnetwork output I r and the input image I . Due to the normality-restoring property of the reconstructive subnetwork, the joint appearance of I and I r differs significantly in anomalous images, providing the information necessary for anomaly segmentation. In reconstruction-based anomaly detection methods anomaly maps are obtained using similarity functions such as SSIM [27] to compare the original image to its reconstruction, however a surface anomaly detection-specific similarity measure is difficult to hand-craft. In contrast, the discriminative sub-network learns the appropriate distance measure automatically. The network outputs an anomaly score map M o of the same size as I . Focal Loss [14] ( L seg ) is applied on the discriminative sub-network output to increase robustness towards accurate segmentation of hard examples.

Considering both the segmentation and the reconstructive objectives of the two sub-networks, the total loss used in training DRÆM is

L ( I, I r , M a , M ) = L rec ( I, I r ) + L seg ( M a , M ) , (3)

where M a and M are the ground truth and the output anomaly segmentation masks, respectively.

## 3.3. Simulated anomaly generation

DRÆM does not require simulations to realistically reflect the real anomaly appearance in the target domain, but rather to generate just-out-of-distribution appearances, which allow learning the appropriate distance function to recognize the anomaly by its deviation from normality. The proposed anomaly simulator follows this paradigm.

A noise image is generated by a Perlin noise generator [18] to capture a variety of anomaly shapes (Figure 4, P ) and binarized by a threshod sampled uniformly at random (Figure 4, M a ) into an anomaly map M a . The anomaly texture source image A is sampled from an anomaly source image dataset which is unrelated to the input image distribution (Figure 4, A ). Random augmentation sampling, inspired by RandAugment [10], is then applied by a set