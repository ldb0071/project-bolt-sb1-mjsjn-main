Page 48

Yang et al. [149] proposed an image anomaly detection method combining Transformer and GAN networks. They integrated an attention module into the depth-wise CNN-based encoder of the GAN to enhance the latent representation of input images. This approach addresses the limitation of the CNN encoder used in GAN-based methods for modeling the long-range information within image data, fusing global attention with local attention. Xiao et al. [150] proposed the S2DWMTrans architecture, which deeply integrates convolutional operations with self-attention operations for anomaly detection in Hyperspectral images. S2DWMTrans consists of 3 main modules: DWMTrans, AWLF (Adaptive-Weighted Loss Function), and Postprocessing. DWMTrans is responsible for extracting spatial-spectral features from both global and local perspectives. AWLF helps control the training trend and further suppress anomalies. Postprocessing calculates the Mahalanobis distance for anomaly detection.

Liu et al. [151] extensively redesigned the Transformer model and proposed a 2-stage based framework called 'decouple and resolve' (DAR), consisting of the temporal proposal producer (TPP) and online anomaly localizer (OAL) modules. The TPP module aims to fully leverage hierarchical temporal relationships among snippets to generate precise pseudo-labels at the snippet level. Subsequently, using the fine-grained supervisory signals generated by TPP, the Transformer-based OAL module is trained to aggregate valuable cues from historical observations and anticipated future semantics to make predictions at the current time step. Both the TPP and OAL modules are jointly trained in a multi-task learning paradigm to share beneficial knowledge, enabling high-precision video anomaly localization tasks. For the same video anomaly detection task, Chen et al. [152] took a different approach and proposed the Magnitude-Contrastive Glance-and-Focus Network (MGFN). MGFN combines the Q , K , and V matrices from the Vanilla Transformer with convolutional operations to form the Glance Block. They also introduced the Feature Amplification Mechanism and a Magnitude Contrastive Loss to enhance the discriminativeness of feature magnitudes for detecting anomalies.

In summary, hybrid models usually integrate Transformer with other auxiliary models (i.e., GAN, VAE, etc.) that already have excellent anomaly detection performance to compensate for the Transformer's disadvantages such as long training time and achieve better comprehensive performance.

## 5 Application scenario of Transformer model in anomaly detection task

Unlike other anomaly detection reviews [1] that classify the application scenarios into intrusion damage detection, medical, and public health anomaly detection, etc, this paper divides the application scenarios of anomaly detection into log, image, sound, video, time series data, flow data, and others according to data types, as shown in Figure 9.